{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13a08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eu_speeches_all_2025-10-16.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a231b",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1830c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkoslowsky/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ===== settings (defaults; can be overridden in run_macro_series) =====\n",
    "TIME_BIN   = \"Y\"   # \"Y\", \"2Y\", \"3Y\"\n",
    "MIN_PER_PARTY = 10\n",
    "NULL_ITERS = 300\n",
    "BOOT_ITERS = 300\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "MAX_DIMS   = 100\n",
    "BOILER = [\n",
    "    \"mr president\",\"madam president\",\"honourable members\",\n",
    "    \"president\",\"commissioner\",\"high representative\",\"thank you\"\n",
    "]\n",
    "\n",
    "# ===== helpers =====\n",
    "\n",
    "def _scrub_boiler(s: str) -> str:\n",
    "    s = str(s).lower()\n",
    "    for b in BOILER:\n",
    "        s = s.replace(b, \" \")\n",
    "    return s\n",
    "\n",
    "def _length_in_tokens(text) -> int:\n",
    "    \"\"\"Crude proxy for speaking time; replace with duration if available.\"\"\"\n",
    "    return max(1, len(str(text).split()))\n",
    "\n",
    "def compute_cpc(X, y, w=None):\n",
    "    \"\"\"\n",
    "    Compute Cluster-Polarization Coefficient (CPC) and adjusted CPC (CPC_adj).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (N, J)\n",
    "        Data matrix (e.g., embeddings or PCA scores).\n",
    "    y : array-like, shape (N,)\n",
    "        Group labels (e.g., party IDs).\n",
    "    w : array-like, shape (N,), optional\n",
    "        Optional non-negative weights. If provided, returns a weighted CPC.\n",
    "        CPC_adj is only computed for the unweighted case (w is None).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stats : dict\n",
    "        {\n",
    "          \"BSS\", \"WSS\", \"TSS\",\n",
    "          \"CPC\", \"CPC_adj\",\n",
    "          \"N\", \"J\", \"K\"\n",
    "        }\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    N, J = X.shape\n",
    "    groups, counts = np.unique(y, return_counts=True)\n",
    "    K = len(groups)\n",
    "\n",
    "    if w is None:\n",
    "        # Unweighted CPC\n",
    "        mu = X.mean(axis=0)\n",
    "        WSS = 0.0\n",
    "        BSS = 0.0\n",
    "        for g, n_g in zip(groups, counts):\n",
    "            Xg = X[y == g]\n",
    "            mug = Xg.mean(axis=0)\n",
    "            WSS += ((Xg - mug) ** 2).sum()\n",
    "            BSS += n_g * ((mug - mu) ** 2).sum()\n",
    "        TSS = BSS + WSS\n",
    "        CPC = BSS / (TSS + 1e-12)\n",
    "\n",
    "        # Adjusted CPC (Equation 3 in Mehlhaff)\n",
    "        if (N > J) and (N > J * K) and (N - J * K) != 0:\n",
    "            CPC_adj = 1.0 - (1.0 - CPC) * (N - J) / (N - J * K)\n",
    "        else:\n",
    "            CPC_adj = np.nan\n",
    "    else:\n",
    "        # Weighted case: CPC is well-defined; CPC_adj is left as NaN\n",
    "        w = np.asarray(w, dtype=float)\n",
    "        w = np.clip(w, 0.0, None)\n",
    "        if w.sum() <= 0:\n",
    "            raise ValueError(\"All weights are zero or negative.\")\n",
    "        W = w / w.sum()\n",
    "\n",
    "        mu = (W[:, None] * X).sum(axis=0)\n",
    "        TSS = (W[:, None] * (X - mu) ** 2).sum()\n",
    "\n",
    "        BSS = 0.0\n",
    "        WSS = 0.0\n",
    "        for g in groups:\n",
    "            m = (y == g)\n",
    "            Wg = W[m]\n",
    "            Xg = X[m]\n",
    "            wg_sum = Wg.sum()\n",
    "            if wg_sum <= 0:\n",
    "                continue\n",
    "            mug = (Wg[:, None] * Xg).sum(axis=0) / wg_sum\n",
    "            WSS += (Wg[:, None] * (Xg - mug) ** 2).sum()\n",
    "            BSS += wg_sum * ((mug - mu) ** 2).sum()\n",
    "\n",
    "        CPC = BSS / (TSS + 1e-12)\n",
    "        CPC_adj = np.nan  # not defined in Mehlhaff for weighted case\n",
    "\n",
    "    return {\n",
    "        \"BSS\": float(BSS),\n",
    "        \"WSS\": float(WSS),\n",
    "        \"TSS\": float(TSS),\n",
    "        \"CPC\": float(CPC),\n",
    "        \"CPC_adj\": float(CPC_adj),\n",
    "        \"N\": int(N),\n",
    "        \"J\": int(J),\n",
    "        \"K\": int(len(groups)),\n",
    "    }\n",
    "\n",
    "def between_within_scatter(X, labels):\n",
    "    \"\"\"Legacy helper returning (BSS, WSS, TSS); thin wrapper around compute_cpc.\"\"\"\n",
    "    stats = compute_cpc(X, labels)\n",
    "    return stats[\"BSS\"], stats[\"WSS\"], stats[\"TSS\"]\n",
    "\n",
    "def bss_tss(X, y):\n",
    "    \"\"\"Legacy helper: returns raw CPC = BSS/TSS (unadjusted).\"\"\"\n",
    "    stats = compute_cpc(X, y)\n",
    "    return stats[\"CPC\"]\n",
    "\n",
    "def _weighted_cpc(X, y, w):\n",
    "    \"\"\"Weighted CPC convenience wrapper.\"\"\"\n",
    "    stats = compute_cpc(X, y, w=w)\n",
    "    return stats[\"CPC\"]\n",
    "\n",
    "def pairwise_std_centroid_dists(X, y):\n",
    "    \"\"\"\n",
    "    Pairwise standardized centroid distances between groups.\n",
    "\n",
    "    Effect-size style metric: ||mu_a - mu_b|| divided by the average\n",
    "    within-group spread of a and b. Not part of CPC; purely descriptive.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    groups = np.unique(y)\n",
    "    cents = {g: X[y == g].mean(axis=0) for g in groups}\n",
    "    pooled = {}\n",
    "    for g in groups:\n",
    "        Xg = X[y == g]\n",
    "        mu = cents[g]\n",
    "        if Xg.shape[0] <= 1:\n",
    "            pooled[g] = 0.0\n",
    "        else:\n",
    "            pooled[g] = float(\n",
    "                np.sqrt(((Xg - mu) ** 2).sum() / max(Xg.shape[0] - 1, 1))\n",
    "            )\n",
    "    rows = []\n",
    "    for i, a in enumerate(groups):\n",
    "        for b in groups[i + 1 :]:\n",
    "            num = float(np.linalg.norm(cents[a] - cents[b]))\n",
    "            denom = 0.5 * (pooled[a] + pooled[b]) + 1e-12\n",
    "            rows.append((a, b, num / denom))\n",
    "    return pd.DataFrame(rows, columns=[\"party_a\", \"party_b\", \"std_dist\"]).sort_values(\n",
    "        \"std_dist\", ascending=False\n",
    "    )\n",
    "\n",
    "def _aggregate_by_speaker(X_bin, df_bin):\n",
    "    \"\"\"Equal weight per speaker (one vector per MEP per bin).\"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for _, g in df_bin.groupby(\"speaker_name\", sort=False):\n",
    "        pos = g.index.to_numpy()  # df_bin must be 0..N-1 (reset_index done upstream)\n",
    "        Xs.append(X_bin[pos].mean(axis=0))\n",
    "        ys.append(g[\"political_group\"].mode().iloc[0])\n",
    "    return np.stack(Xs), np.array(ys)\n",
    "\n",
    "def _build_speech_matrix(X_bin, d_bin, cap_per_speaker=5):\n",
    "    \"\"\"\n",
    "    Speech-level design with a per-speaker cap to avoid dominance.\n",
    "    Returns: X_use, y_use, spk_ids, lg_use, tp_use, w_use  (aligned arrays)\n",
    "    \"\"\"\n",
    "    take_idx, spk_codes = [], []\n",
    "    spk_cats = pd.Categorical(d_bin[\"speaker_name\"].astype(str))\n",
    "    spk_id_all = spk_cats.codes  # 0..S-1 for all rows\n",
    "\n",
    "    # take first `cap_per_speaker` speeches per speaker (stable order)\n",
    "    for sid in np.unique(spk_id_all):\n",
    "        idxs = np.where(spk_id_all == sid)[0]\n",
    "        take_idx.extend(idxs[:cap_per_speaker])\n",
    "        spk_codes.extend([sid] * min(len(idxs), cap_per_speaker))\n",
    "\n",
    "    if not take_idx:\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    take_idx = np.array(take_idx, dtype=int)\n",
    "    spk_codes = np.array(spk_codes, dtype=int)\n",
    "\n",
    "    X_use = X_bin[take_idx]\n",
    "    y_use = d_bin[\"political_group\"].astype(str).iloc[take_idx].values\n",
    "    lg_use = d_bin[\"language\"].astype(str).iloc[take_idx].values\n",
    "    tp_use = d_bin[\"topic\"].astype(str).iloc[take_idx].values\n",
    "    w_use = np.array(\n",
    "        [_length_in_tokens(t) for t in d_bin[\"speech_content\"].iloc[take_idx]],\n",
    "        dtype=float,\n",
    "    )\n",
    "    return X_use, y_use, spk_codes, lg_use, tp_use, w_use\n",
    "\n",
    "# ===== main: multilingual, language-centered, agenda-controlled =====\n",
    "\n",
    "def run_macro_series(\n",
    "    df,\n",
    "    macro_topic,\n",
    "    languages=None,\n",
    "    *,\n",
    "    # mode switch:\n",
    "    mode=\"speaker\",                 # \"speaker\" | \"speech_capped\" | \"speech_weighted\"\n",
    "    cap_per_speaker=5,              # used only if mode==\"speech_capped\"\n",
    "    keep_min_speakers=0,            # speaker-mode only: drop parties with < keep_min_speakers speakers (0 = off)\n",
    "    min_speeches_per_party=30,      # speech_* modes: min speeches/party/bin (after cap for speech_capped)\n",
    "    min_unique_speakers_per_party=5,# speech_* modes: also require ≥ this many distinct speakers/party/bin\n",
    "    require_parties=3,              # both modes: require at least this many parties kept\n",
    "    weight_by=\"count\",              # speech_weighted only: \"count\" or \"tokens\"\n",
    "    demean_level=\"language_topic\",  # \"language_topic\" (default), \"language\", or None\n",
    "    shuffle_strata=\"language_topic\",# \"language_topic\" | \"language\" | \"topic\" | None\n",
    "    drop_parties=(\"ID\",),           # parties to drop; set to None or () to keep all\n",
    "    time_bin=None,                  # override global TIME_BIN if not None\n",
    "    model_name=None,                # override global MODEL_NAME if not None\n",
    "    pca_max_dims=None,              # override global MAX_DIMS if not None\n",
    "    use_cpc_adj=True,               # if True, z/CI are based on CPC_adj when defined, else CPC\n",
    "    null_iters=None,\n",
    "    boot_iters=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the Mehlhaff-style CPC pipeline on a macro-topic slice (or ALL).\n",
    "\n",
    "    Core behaviour:\n",
    "    - Same 3 modes as V5.1 (speaker / speech_capped / speech_weighted).\n",
    "    - One multilingual embedding + PCA per macro slice.\n",
    "    - Demeaning by language / language×topic as before.\n",
    "    - Cluster-aware permutation null and bootstrap CIs.\n",
    "\n",
    "    Changes vs V5:\n",
    "    - Uses compute_cpc() to return CPC and CPC_adj.\n",
    "    - Stores BSS, WSS, TSS, CPC, CPC_adj in the result.\n",
    "    - The `obs_bss_tss` column now contains the *used* measure:\n",
    "      CPC_adj (preferred) or CPC if CPC_adj is undefined.\n",
    "    \"\"\"\n",
    "    # resolve defaults\n",
    "    if time_bin is None:\n",
    "        time_bin = TIME_BIN\n",
    "    if model_name is None:\n",
    "        model_name = MODEL_NAME\n",
    "    if pca_max_dims is None:\n",
    "        pca_max_dims = MAX_DIMS\n",
    "    if null_iters is None:\n",
    "        null_iters = NULL_ITERS\n",
    "    if boot_iters is None:\n",
    "        boot_iters = BOOT_ITERS\n",
    "\n",
    "    # ---- filter / hygiene ----\n",
    "    if (macro_topic is None) or (str(macro_topic).lower() in {\"all\", \"__all__\", \"overall\"}):\n",
    "        d = df.copy()\n",
    "        macro_label = \"All speeches\"\n",
    "    else:\n",
    "        d = df[df[\"macro_topic\"] == macro_topic].copy()\n",
    "        macro_label = macro_topic\n",
    "\n",
    "    if languages is not None:\n",
    "        d = d[d[\"language\"].isin(languages)].copy()\n",
    "\n",
    "    d = d.dropna(\n",
    "        subset=[\"political_group\", \"speech_content\", \"speaker_name\", \"topic\", \"language\", \"date\"]\n",
    "    )\n",
    "    d = d[d[\"speech_content\"].astype(str).str.len() >= 40]\n",
    "\n",
    "    if drop_parties:\n",
    "        d = d[~d[\"political_group\"].isin(drop_parties)].copy()\n",
    "\n",
    "    d[\"time_bin\"] = pd.to_datetime(d[\"date\"]).dt.to_period(time_bin).dt.to_timestamp()\n",
    "    d = d.reset_index(drop=True)\n",
    "\n",
    "    if d.empty:\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"languages\",\"macro_topic\",\"time_bin\",\"ok\",\"reason\",\n",
    "                \"obs_bss_tss\",\"cpc\",\"cpc_adj\",\"bss\",\"wss\",\"tss\",\n",
    "                \"null_mean\",\"null_sd\",\"z\",\"ci_lo\",\"ci_hi\",\n",
    "                \"n_docs\",\"n_parties\",\"counts\",\"mode\",\"weight_by\"\n",
    "            ]\n",
    "        ), None\n",
    "\n",
    "    # ---- Embed once for the whole slice (multilingual) ----\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.max_seq_length = 512\n",
    "    texts = d[\"speech_content\"].astype(str).map(_scrub_boiler).tolist()\n",
    "    E = model.encode(\n",
    "        texts,\n",
    "        batch_size=32,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "\n",
    "    # ---- Remove language / agenda offsets before PCA (controlled by demean_level) ----\n",
    "    langs = d[\"language\"].astype(str).values\n",
    "    topics = d[\"topic\"].astype(str).values\n",
    "\n",
    "    E_adj = E.copy()\n",
    "    if demean_level in {\"language\", \"language_topic\"}:\n",
    "        # (a) center within language\n",
    "        for lg in np.unique(langs):\n",
    "            m = (langs == lg)\n",
    "            if m.any():\n",
    "                E_adj[m] -= E_adj[m].mean(axis=0, keepdims=True)\n",
    "    if demean_level == \"language_topic\":\n",
    "        # (b) finer: center within (language × micro-topic)\n",
    "        for lg in np.unique(langs):\n",
    "            for tp in np.unique(topics):\n",
    "                m = (langs == lg) & (topics == tp)\n",
    "                if m.any():\n",
    "                    E_adj[m] -= E_adj[m].mean(axis=0, keepdims=True)\n",
    "    # if demean_level is None → no de-meaning\n",
    "\n",
    "    # global center + PCA once (bins comparable)\n",
    "    E_c = E_adj - E_adj.mean(axis=0, keepdims=True)\n",
    "    n_samples, n_features = E_c.shape\n",
    "    pca_k = max(2, min(pca_max_dims, n_features, n_samples - 1))\n",
    "    pca = PCA(n_components=pca_k, random_state=42).fit(E_c)\n",
    "    E_p = pca.transform(E_c)\n",
    "\n",
    "    rows = []\n",
    "    pw = None\n",
    "\n",
    "    # helper to choose obs metric\n",
    "    def _pick(obs_stats):\n",
    "        cpc_raw = obs_stats[\"CPC\"]\n",
    "        cpc_adj = obs_stats[\"CPC_adj\"]\n",
    "        if use_cpc_adj and np.isfinite(cpc_adj):\n",
    "            return cpc_adj\n",
    "        return cpc_raw\n",
    "\n",
    "    # ---- Per-bin loop ----\n",
    "    for bin_val, g in d.groupby(\"time_bin\", sort=True):\n",
    "        idx = g.index.to_numpy()\n",
    "        X_bin = E_p[idx]\n",
    "        d_bin = d.iloc[idx].copy().reset_index(drop=True)\n",
    "\n",
    "        if d_bin.empty:\n",
    "            continue\n",
    "\n",
    "        # ===== MODE: SPEAKER =====\n",
    "        if mode == \"speaker\":\n",
    "            X_mat, y_lab = _aggregate_by_speaker(X_bin, d_bin)\n",
    "            counts = pd.Series(y_lab).value_counts()\n",
    "\n",
    "            if keep_min_speakers and keep_min_speakers > 0:\n",
    "                keep = counts[counts >= keep_min_speakers].index\n",
    "                sel = np.isin(y_lab, keep)\n",
    "                X_mat, y_lab = X_mat[sel], y_lab[sel]\n",
    "                counts = pd.Series(y_lab).value_counts()\n",
    "\n",
    "            ok_bin = (len(counts) >= require_parties) and (counts.min() >= MIN_PER_PARTY)\n",
    "\n",
    "            if not ok_bin:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"languages\": \",\".join(sorted(d_bin[\"language\"].unique())),\n",
    "                        \"macro_topic\": macro_label,\n",
    "                        \"time_bin\": bin_val,\n",
    "                        \"ok\": False,\n",
    "                        \"reason\": \"low_n\",\n",
    "                        \"obs_bss_tss\": np.nan,\n",
    "                        \"cpc\": np.nan,\n",
    "                        \"cpc_adj\": np.nan,\n",
    "                        \"bss\": np.nan,\n",
    "                        \"wss\": np.nan,\n",
    "                        \"tss\": np.nan,\n",
    "                        \"null_mean\": np.nan,\n",
    "                        \"null_sd\": np.nan,\n",
    "                        \"z\": np.nan,\n",
    "                        \"ci_lo\": np.nan,\n",
    "                        \"ci_hi\": np.nan,\n",
    "                        \"n_docs\": int(len(y_lab)),\n",
    "                        \"n_parties\": int(len(counts)),\n",
    "                        \"counts\": counts.to_dict(),\n",
    "                        \"mode\": mode,\n",
    "                        \"weight_by\": None,\n",
    "                    }\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # observed CPC / CPC_adj\n",
    "            obs_stats = compute_cpc(X_mat, y_lab)\n",
    "            obs_val = _pick(obs_stats)\n",
    "\n",
    "            # permutation: stratify; shuffle at SPEAKER level\n",
    "            rng = np.random.default_rng(42)\n",
    "            spk = d_bin.groupby(\"speaker_name\", sort=False)[\"political_group\"].agg(\n",
    "                lambda x: x.mode().iloc[0]\n",
    "            ).astype(str)\n",
    "            spk_lg = d_bin.groupby(\"speaker_name\", sort=False)[\"language\"].agg(\n",
    "                lambda x: x.mode().iloc[0]\n",
    "            ).astype(str)\n",
    "            spk_tp = d_bin.groupby(\"speaker_name\", sort=False)[\"topic\"].agg(\n",
    "                lambda x: x.mode().iloc[0]\n",
    "            ).astype(str)\n",
    "            spk_df = pd.DataFrame(\n",
    "                {\"lab\": spk.values, \"lg\": spk_lg.values, \"tp\": spk_tp.values},\n",
    "                index=spk.index,\n",
    "            )\n",
    "\n",
    "            nulls = []\n",
    "            for _ in range(null_iters):\n",
    "                perm = spk_df[\"lab\"].copy()\n",
    "                if shuffle_strata == \"language_topic\":\n",
    "                    groups = spk_df.groupby([\"lg\", \"tp\"], sort=False)\n",
    "                elif shuffle_strata == \"language\":\n",
    "                    groups = spk_df.groupby([\"lg\"], sort=False)\n",
    "                elif shuffle_strata == \"topic\":\n",
    "                    groups = spk_df.groupby([\"tp\"], sort=False)\n",
    "                else:\n",
    "                    groups = [(\"_all\", spk_df)]\n",
    "                for _, block in groups:\n",
    "                    vals = block[\"lab\"].to_numpy().copy()\n",
    "                    rng.shuffle(vals)\n",
    "                    perm.loc[block.index] = vals\n",
    "                y_perm = perm.values\n",
    "                perm_stats = compute_cpc(X_mat, y_perm)\n",
    "                nulls.append(_pick(perm_stats))\n",
    "            nulls = np.array(nulls)\n",
    "            null_mean = float(nulls.mean())\n",
    "            null_sd = float(nulls.std(ddof=1))\n",
    "\n",
    "            # cluster bootstrap by speaker\n",
    "            rngb = np.random.default_rng(1000)\n",
    "            n_spk = len(y_lab)\n",
    "            boots = []\n",
    "            for _ in range(boot_iters):\n",
    "                b = rngb.integers(0, n_spk, size=n_spk)\n",
    "                boot_stats = compute_cpc(X_mat[b], y_lab[b])\n",
    "                boots.append(_pick(boot_stats))\n",
    "            lo, hi = np.percentile(boots, [2.5, 97.5])\n",
    "\n",
    "        # ===== MODE: SPEECH (capped) =====\n",
    "        elif mode == \"speech_capped\":\n",
    "            out = _build_speech_matrix(X_bin, d_bin, cap_per_speaker=cap_per_speaker)\n",
    "            X_use, y_use, spk_ids, lg_use, tp_use, w_use = out\n",
    "            if X_use is None:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"languages\": \",\".join(sorted(d_bin[\"language\"].unique())),\n",
    "                        \"macro_topic\": macro_label,\n",
    "                        \"time_bin\": bin_val,\n",
    "                        \"ok\": False,\n",
    "                        \"reason\": \"empty\",\n",
    "                        \"obs_bss_tss\": np.nan,\n",
    "                        \"cpc\": np.nan,\n",
    "                        \"cpc_adj\": np.nan,\n",
    "                        \"bss\": np.nan,\n",
    "                        \"wss\": np.nan,\n",
    "                        \"tss\": np.nan,\n",
    "                        \"null_mean\": np.nan,\n",
    "                        \"null_sd\": np.nan,\n",
    "                        \"z\": np.nan,\n",
    "                        \"ci_lo\": np.nan,\n",
    "                        \"ci_hi\": np.nan,\n",
    "                        \"n_docs\": 0,\n",
    "                        \"n_parties\": 0,\n",
    "                        \"counts\": {},\n",
    "                        \"mode\": mode,\n",
    "                        \"weight_by\": None,\n",
    "                    }\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            counts_speech = pd.Series(y_use).value_counts()\n",
    "            spk_party = pd.Series(spk_ids).groupby(pd.Series(y_use)).nunique()\n",
    "\n",
    "            keep_parties = [\n",
    "                p\n",
    "                for p in counts_speech.index\n",
    "                if (counts_speech.get(p, 0) >= min_speeches_per_party)\n",
    "                and (spk_party.get(p, 0) >= min_unique_speakers_per_party)\n",
    "            ]\n",
    "\n",
    "            m = np.isin(y_use, keep_parties)\n",
    "            X_mat, y_lab = X_use[m], y_use[m]\n",
    "            spk_ids, lg_use, tp_use, w_use = (\n",
    "                spk_ids[m],\n",
    "                lg_use[m],\n",
    "                tp_use[m],\n",
    "                w_use[m],\n",
    "            )\n",
    "            counts = pd.Series(y_lab).value_counts()\n",
    "            ok_bin = len(counts) >= require_parties\n",
    "\n",
    "            if not ok_bin:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"languages\": \",\".join(sorted(d_bin[\"language\"].unique())),\n",
    "                        \"macro_topic\": macro_label,\n",
    "                        \"time_bin\": bin_val,\n",
    "                        \"ok\": False,\n",
    "                        \"reason\": \"low_n\",\n",
    "                        \"obs_bss_tss\": np.nan,\n",
    "                        \"cpc\": np.nan,\n",
    "                        \"cpc_adj\": np.nan,\n",
    "                        \"bss\": np.nan,\n",
    "                        \"wss\": np.nan,\n",
    "                        \"tss\": np.nan,\n",
    "                        \"null_mean\": np.nan,\n",
    "                        \"null_sd\": np.nan,\n",
    "                        \"z\": np.nan,\n",
    "                        \"ci_lo\": np.nan,\n",
    "                        \"ci_hi\": np.nan,\n",
    "                        \"n_docs\": int(len(y_lab)),\n",
    "                        \"n_parties\": int(len(counts)),\n",
    "                        \"counts\": counts.to_dict(),\n",
    "                        \"mode\": mode,\n",
    "                        \"weight_by\": None,\n",
    "                    }\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            obs_stats = compute_cpc(X_mat, y_lab)\n",
    "            obs_val = _pick(obs_stats)\n",
    "\n",
    "            # permutation (clustered by speaker)\n",
    "            rng = np.random.default_rng(42)\n",
    "            sel = pd.DataFrame(\n",
    "                {\"spk\": spk_ids, \"lab\": y_lab, \"lg\": lg_use, \"tp\": tp_use}\n",
    "            )\n",
    "            spk_major = sel.groupby(\"spk\", sort=False)[\"lab\"].agg(\n",
    "                lambda x: x.mode().iloc[0]\n",
    "            )\n",
    "            spk_meta = sel.groupby(\"spk\", sort=False)[[\"lg\", \"tp\"]].agg(\n",
    "                lambda x: x.iloc[0]\n",
    "            )\n",
    "\n",
    "            nulls = []\n",
    "            for _ in range(null_iters):\n",
    "                perm_spk_lab = spk_major.copy()\n",
    "                if shuffle_strata == \"language_topic\":\n",
    "                    groups = spk_meta.groupby([\"lg\", \"tp\"], sort=False)\n",
    "                elif shuffle_strata == \"language\":\n",
    "                    groups = spk_meta.groupby([\"lg\"], sort=False)\n",
    "                elif shuffle_strata == \"topic\":\n",
    "                    groups = spk_meta.groupby([\"tp\"], sort=False)\n",
    "                else:\n",
    "                    groups = [(\"_all\", spk_meta)]\n",
    "                for _, block in groups:\n",
    "                    vals = perm_spk_lab.loc[block.index].to_numpy().copy()\n",
    "                    rng.shuffle(vals)\n",
    "                    perm_spk_lab.loc[block.index] = vals\n",
    "                y_perm = sel[\"spk\"].map(perm_spk_lab).to_numpy()\n",
    "                perm_stats = compute_cpc(X_mat, y_perm)\n",
    "                nulls.append(_pick(perm_stats))\n",
    "            nulls = np.array(nulls)\n",
    "            null_mean = float(nulls.mean())\n",
    "            null_sd = float(nulls.std(ddof=1))\n",
    "\n",
    "            # clustered bootstrap by speaker\n",
    "            rngb = np.random.default_rng(1000)\n",
    "            unique_spk = np.unique(spk_ids)\n",
    "            boots = []\n",
    "            for _ in range(boot_iters):\n",
    "                draw = rngb.choice(unique_spk, size=len(unique_spk), replace=True)\n",
    "                take = np.isin(spk_ids, draw)\n",
    "                boot_stats = compute_cpc(X_mat[take], y_lab[take])\n",
    "                boots.append(_pick(boot_stats))\n",
    "            lo, hi = np.percentile(boots, [2.5, 97.5])\n",
    "\n",
    "        # ===== MODE: SPEECH (weighted; ALL speeches) =====\n",
    "        elif mode == \"speech_weighted\":\n",
    "            X_mat = X_bin\n",
    "            y_lab = d_bin[\"political_group\"].astype(str).values\n",
    "            if weight_by == \"tokens\":\n",
    "                w = np.array(\n",
    "                    [_length_in_tokens(t) for t in d_bin[\"speech_content\"]],\n",
    "                    dtype=float,\n",
    "                )\n",
    "            else:\n",
    "                w = None\n",
    "\n",
    "            counts_speech = pd.Series(y_lab).value_counts()\n",
    "            uniq_spk_per_party = d_bin.groupby(\"political_group\")[\"speaker_name\"].nunique()\n",
    "            keep_parties = [\n",
    "                p\n",
    "                for p in counts_speech.index\n",
    "                if (counts_speech.get(p, 0) >= min_speeches_per_party)\n",
    "                and (uniq_spk_per_party.get(p, 0) >= min_unique_speakers_per_party)\n",
    "            ]\n",
    "            sel = np.isin(y_lab, keep_parties)\n",
    "            X_mat, y_lab = X_mat[sel], y_lab[sel]\n",
    "            w = None if w is None else w[sel]\n",
    "            counts = pd.Series(y_lab).value_counts()\n",
    "            ok_bin = len(counts) >= require_parties\n",
    "\n",
    "            if not ok_bin:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"languages\": \",\".join(sorted(d_bin[\"language\"].unique())),\n",
    "                        \"macro_topic\": macro_label,\n",
    "                        \"time_bin\": bin_val,\n",
    "                        \"ok\": False,\n",
    "                        \"reason\": \"low_n\",\n",
    "                        \"obs_bss_tss\": np.nan,\n",
    "                        \"cpc\": np.nan,\n",
    "                        \"cpc_adj\": np.nan,\n",
    "                        \"bss\": np.nan,\n",
    "                        \"wss\": np.nan,\n",
    "                        \"tss\": np.nan,\n",
    "                        \"null_mean\": np.nan,\n",
    "                        \"null_sd\": np.nan,\n",
    "                        \"z\": np.nan,\n",
    "                        \"ci_lo\": np.nan,\n",
    "                        \"ci_hi\": np.nan,\n",
    "                        \"n_docs\": int(len(y_lab)),\n",
    "                        \"n_parties\": int(len(counts)),\n",
    "                        \"counts\": counts.to_dict(),\n",
    "                        \"mode\": mode,\n",
    "                        \"weight_by\": weight_by,\n",
    "                    }\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # weighted CPC (CPC_adj left NaN when weights used)\n",
    "            obs_stats = compute_cpc(X_mat, y_lab, w=w)\n",
    "            obs_val = _pick(obs_stats)\n",
    "\n",
    "            rng = np.random.default_rng(42)\n",
    "            spk_cats = pd.Categorical(d_bin[\"speaker_name\"].astype(str).iloc[sel])\n",
    "            spk_ids = spk_cats.codes\n",
    "            lg_use = d_bin[\"language\"].astype(str).iloc[sel].values\n",
    "            tp_use = d_bin[\"topic\"].astype(str).iloc[sel].values\n",
    "\n",
    "            sel_df = pd.DataFrame(\n",
    "                {\"spk\": spk_ids, \"lab\": y_lab, \"lg\": lg_use, \"tp\": tp_use}\n",
    "            )\n",
    "            spk_major = sel_df.groupby(\"spk\", sort=False)[\"lab\"].agg(\n",
    "                lambda x: x.mode().iloc[0]\n",
    "            )\n",
    "            spk_meta = sel_df.groupby(\"spk\", sort=False)[[\"lg\", \"tp\"]].agg(\n",
    "                lambda x: x.iloc[0]\n",
    "            )\n",
    "\n",
    "            nulls = []\n",
    "            for _ in range(null_iters):\n",
    "                perm_spk_lab = spk_major.copy()\n",
    "                if shuffle_strata == \"language_topic\":\n",
    "                    groups = spk_meta.groupby([\"lg\", \"tp\"], sort=False)\n",
    "                elif shuffle_strata == \"language\":\n",
    "                    groups = spk_meta.groupby([\"lg\"], sort=False)\n",
    "                elif shuffle_strata == \"topic\":\n",
    "                    groups = spk_meta.groupby([\"tp\"], sort=False)\n",
    "                else:\n",
    "                    groups = [(\"_all\", spk_meta)]\n",
    "                for _, block in groups:\n",
    "                    vals = perm_spk_lab.loc[block.index].to_numpy().copy()\n",
    "                    rng.shuffle(vals)\n",
    "                    perm_spk_lab.loc[block.index] = vals\n",
    "                y_perm = sel_df[\"spk\"].map(perm_spk_lab).to_numpy()\n",
    "                perm_stats = compute_cpc(X_mat, y_perm, w=w)\n",
    "                nulls.append(_pick(perm_stats))\n",
    "            nulls = np.array(nulls)\n",
    "            null_mean = float(nulls.mean())\n",
    "            null_sd = float(nulls.std(ddof=1))\n",
    "\n",
    "            # clustered bootstrap by speaker\n",
    "            rngb = np.random.default_rng(1000)\n",
    "            unique_spk = np.unique(spk_ids)\n",
    "            boots = []\n",
    "            for _ in range(boot_iters):\n",
    "                draw = rngb.choice(unique_spk, size=len(unique_spk), replace=True)\n",
    "                take = np.isin(spk_ids, draw)\n",
    "                boot_stats = compute_cpc(\n",
    "                    X_mat[take],\n",
    "                    y_lab[take],\n",
    "                    w=None if w is None else w[take],\n",
    "                )\n",
    "                boots.append(_pick(boot_stats))\n",
    "            lo, hi = np.percentile(boots, [2.5, 97.5])\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'speaker', 'speech_capped', or 'speech_weighted'\")\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"languages\": \",\".join(sorted(d_bin[\"language\"].unique())),\n",
    "                \"macro_topic\": macro_label,\n",
    "                \"time_bin\": bin_val,\n",
    "                \"ok\": True,\n",
    "                \"reason\": None,\n",
    "                \"obs_bss_tss\": float(obs_val),\n",
    "                \"cpc\": float(obs_stats[\"CPC\"]),\n",
    "                \"cpc_adj\": float(obs_stats[\"CPC_adj\"]),\n",
    "                \"bss\": float(obs_stats[\"BSS\"]),\n",
    "                \"wss\": float(obs_stats[\"WSS\"]),\n",
    "                \"tss\": float(obs_stats[\"TSS\"]),\n",
    "                \"null_mean\": float(null_mean),\n",
    "                \"null_sd\": float(null_sd),\n",
    "                \"z\": float((obs_val - null_mean) / (null_sd + 1e-12)),\n",
    "                \"ci_lo\": float(lo),\n",
    "                \"ci_hi\": float(hi),\n",
    "                \"n_docs\": int(X_mat.shape[0]),\n",
    "                \"n_parties\": int(len(counts)),\n",
    "                \"counts\": counts.to_dict(),\n",
    "                \"mode\": mode,\n",
    "                \"weight_by\": (weight_by if mode == \"speech_weighted\" else None),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    res = pd.DataFrame(rows).sort_values(\"time_bin\")\n",
    "\n",
    "    # ---- Pairwise distances for latest valid bin (same unit as active mode) ----\n",
    "    valid = res[res[\"ok\"]]\n",
    "    if not valid.empty:\n",
    "        latest_bin = valid[\"time_bin\"].max()\n",
    "        idx = d.index[d[\"time_bin\"] == latest_bin].to_numpy()\n",
    "        X_bin = E_p[idx]\n",
    "        d_bin = d.iloc[idx].copy().reset_index(drop=True)\n",
    "\n",
    "        if mode == \"speaker\":\n",
    "            X_latest, y_latest = _aggregate_by_speaker(X_bin, d_bin)\n",
    "\n",
    "        elif mode == \"speech_capped\":\n",
    "            out = _build_speech_matrix(X_bin, d_bin, cap_per_speaker=cap_per_speaker)\n",
    "            X_use, y_use, spk_ids, lg_use, tp_use, w_use = out\n",
    "            if X_use is None:\n",
    "                return res, None\n",
    "            counts_speech = pd.Series(y_use).value_counts()\n",
    "            spk_party = pd.Series(spk_ids).groupby(pd.Series(y_use)).nunique()\n",
    "            keep_parties = [\n",
    "                p\n",
    "                for p in counts_speech.index\n",
    "                if (counts_speech.get(p, 0) >= min_speeches_per_party)\n",
    "                and (spk_party.get(p, 0) >= min_unique_speakers_per_party)\n",
    "            ]\n",
    "            m = np.isin(y_use, keep_parties)\n",
    "            X_latest, y_latest = X_use[m], y_use[m]\n",
    "\n",
    "        else:  # speech_weighted\n",
    "            X_latest = X_bin\n",
    "            y_latest = d_bin[\"political_group\"].astype(str).values\n",
    "            counts_speech = pd.Series(y_latest).value_counts()\n",
    "            uniq_spk_per_party = d_bin.groupby(\"political_group\")[\"speaker_name\"].nunique()\n",
    "            keep_parties = [\n",
    "                p\n",
    "                for p in counts_speech.index\n",
    "                if (counts_speech.get(p, 0) >= min_speeches_per_party)\n",
    "                and (uniq_spk_per_party.get(p, 0) >= min_unique_speakers_per_party)\n",
    "            ]\n",
    "            m = np.isin(y_latest, keep_parties)\n",
    "            X_latest, y_latest = X_latest[m], y_latest[m]\n",
    "\n",
    "        if len(np.unique(y_latest)) >= 2:\n",
    "            pw = pairwise_std_centroid_dists(X_latest, y_latest)\n",
    "        else:\n",
    "            pw = None\n",
    "    else:\n",
    "        pw = None\n",
    "\n",
    "    return res, pw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4996e35",
   "metadata": {},
   "source": [
    "# Run all topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196305e6",
   "metadata": {},
   "source": [
    "### Mashine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97adea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# EP Polarization: V6 Batch Runner (VERBOSE)\n",
    "# =========================\n",
    "# Prereqs in memory: df, run_macro_series (V6 version)\n",
    "# Creates per-topic folders under reports_v6/<topic-slug>/ with CSVs + a one-page PDF,\n",
    "# plus an ALL-speeches slice under reports_v6/_all_speeches/.\n",
    "\n",
    "import os, re, sys, time, math, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # headless-safe\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# ---------- Pretty logging ----------\n",
    "def _now():\n",
    "    return dt.datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "def log(msg):\n",
    "    print(f\"[{_now()}] {msg}\", flush=True)\n",
    "\n",
    "# ---------- Progress bar helper ----------\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    tqdm = None\n",
    "\n",
    "def _progress(iterable, desc):\n",
    "    if tqdm is not None:\n",
    "        return tqdm(iterable, desc=desc, ncols=100)\n",
    "    log(desc); return iterable\n",
    "\n",
    "# ---------- Topics (deduped + normalized) ----------\n",
    "RAW_TOPICS = [\n",
    "    \"Agriculture & fisheries\",\n",
    "    \"Climate, environment & biodiversity\",\n",
    "    \"Development & humanitarian aid\",\n",
    "    \"Digital policy & data protection\",\n",
    "    \"EU budget & MFF\",\n",
    "    \"Economy & industrial policy\",\n",
    "    \"Education, culture & sport\",\n",
    "    \"Energy & energy security\",\n",
    "    \"Enlargement & neighbourhood policy\",\n",
    "    \"Foreign policy — Americas\",\n",
    "    \"Foreign policy — Asia-Pacific\",\n",
    "    \"Foreign policy — Europe & Eastern Neighbourhood\",\n",
    "    \"Foreign policy — Middle East & North Africa\",\n",
    "    \"Foreign policy — Sub-Saharan Africa\",\n",
    "    \"Health\",\n",
    "    \"Institutional affairs & governance\",\n",
    "    \"Justice, security & policing\",\n",
    "    \"Media, information & disinformation\",\n",
    "    \"Migration & asylum\",\n",
    "    \"Monetary & financial stability\",\n",
    "    \"Procedural & Parliamentary business\",\n",
    "    \"Research, innovation & space\",\n",
    "    \"Rule of law & fundamental rights\",\n",
    "    \"Security & defence\",\n",
    "    \"Security & policing\",\n",
    "    \"Single market, competition & consumer protection\",\n",
    "    \"Social policy & employment\",\n",
    "    \"Taxation & anti–money laundering\",\n",
    "    \"Trade & globalization\",\n",
    "    \"Transport & mobility\",\n",
    "]\n",
    "\n",
    "def _normalize_topic(t):\n",
    "    t = t.replace(\"&amp;\", \"&\")\n",
    "    t = t.replace(\"\\u2011\", \"-\")   # non-breaking hyphen → hyphen\n",
    "    t = t.replace(\"\\u2013\", \"-\")   # en dash → hyphen\n",
    "    t = t.replace(\"\\u2014\", \"—\")   # keep em dash for display\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "TOPICS = sorted(set(_normalize_topic(t) for t in RAW_TOPICS))\n",
    "\n",
    "# ---------- Filenames & folders ----------\n",
    "BASE_DIR = \"reports_v6\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "def _slugify(name: str) -> str:\n",
    "    s = name.lower()\n",
    "    s = s.replace(\"&\", \"and\")\n",
    "    s = re.sub(r\"[^\\w\\s-]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \"-\", s).strip(\"-\")\n",
    "    s = re.sub(r\"-+\", \"-\", s)\n",
    "    return s\n",
    "\n",
    "# ---------- Robust plotting helpers ----------\n",
    "def _ensure_time_and_numeric(df):\n",
    "    df = df.copy()\n",
    "    if \"time_bin\" in df:\n",
    "        df[\"time_bin\"] = pd.to_datetime(df[\"time_bin\"], errors=\"coerce\")\n",
    "    for col in [\"obs_bss_tss\",\"ci_lo\",\"ci_hi\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _split_ok_low(df):\n",
    "    if \"ok\" not in df.columns:\n",
    "        ok = df.copy(); low = df.iloc[0:0].copy()\n",
    "    else:\n",
    "        ok  = df[df[\"ok\"]==True].copy()\n",
    "        low = df[df[\"ok\"]!=True].copy()\n",
    "    ok  = ok.sort_values(\"time_bin\")\n",
    "    low = low.sort_values(\"time_bin\")\n",
    "    return ok, low\n",
    "\n",
    "def _shared_ylim(res_list):\n",
    "    hi = []\n",
    "    for r in res_list:\n",
    "        r = _ensure_time_and_numeric(r)\n",
    "        ok, _ = _split_ok_low(r)\n",
    "        if not ok.empty:\n",
    "            if \"ci_hi\" in ok:\n",
    "                hi.extend(ok[\"ci_hi\"].dropna().tolist())\n",
    "            elif \"obs_bss_tss\" in ok:\n",
    "                hi.extend(ok[\"obs_bss_tss\"].dropna().tolist())\n",
    "    ymax = max(hi) if hi else 0.05\n",
    "    return (0, ymax * 1.15)\n",
    "\n",
    "def _heat_cbar_limits(pw_list):\n",
    "    mx = 0.0\n",
    "    for pw in pw_list:\n",
    "        if pw is None or len(pw)==0 or \"std_dist\" not in (pw.columns if hasattr(pw, \"columns\") else []): \n",
    "            continue\n",
    "        vals = pd.to_numeric(pw[\"std_dist\"], errors=\"coerce\").dropna()\n",
    "        if not vals.empty: mx = max(mx, float(vals.max()))\n",
    "    if mx <= 0: mx = 0.01\n",
    "    return (0.0, mx)\n",
    "\n",
    "def plot_time_series(ax, res_df, title, show_legend=False, ylim=None):\n",
    "    df = _ensure_time_and_numeric(res_df)\n",
    "    ok, low = _split_ok_low(df)\n",
    "    drew = False\n",
    "\n",
    "    if not ok.empty and {\"time_bin\",\"obs_bss_tss\"} <= set(ok.columns):\n",
    "        if {\"ci_lo\",\"ci_hi\"} <= set(ok.columns):\n",
    "            x_ord = mdates.date2num(ok[\"time_bin\"])\n",
    "            ax.fill_between(x_ord, ok[\"ci_lo\"].values, ok[\"ci_hi\"].values, alpha=0.2, label=\"95% CI\")\n",
    "        ax.plot(ok[\"time_bin\"], ok[\"obs_bss_tss\"], marker=\"o\", lw=1.8, label=\"CPC (adj/unadj)\")\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator(base=2))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "        drew = True\n",
    "\n",
    "    if not low.empty and \"time_bin\" in low:\n",
    "        ax.scatter(low[\"time_bin\"], np.zeros(len(low)), facecolors=\"none\", edgecolors=\"grey\", lw=1.0, label=\"low_n\")\n",
    "        drew = True\n",
    "\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    ax.set_ylabel(\"CPC\"); ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    if ylim: ax.set_ylim(*ylim)\n",
    "    ax.grid(alpha=0.25)\n",
    "\n",
    "    if show_legend and drew:\n",
    "        ax.legend(loc=\"upper left\", fontsize=8, frameon=False)\n",
    "    if not drew:\n",
    "        ax.axis(\"off\"); ax.text(0.5, 0.5, \"No valid rows\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "\n",
    "def plot_heatmap(ax, pw_df, title, vmin=0.0, vmax=0.4):\n",
    "    if pw_df is None or len(pw_df)==0 or {\"party_a\",\"party_b\",\"std_dist\"} - set(pw_df.columns):\n",
    "        ax.axis(\"off\"); ax.set_title(title, fontsize=11)\n",
    "        ax.text(0.5, 0.5, \"No pairwise table for latest valid bin.\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    d = pw_df.copy()\n",
    "    d[\"std_dist\"] = pd.to_numeric(d[\"std_dist\"], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[\"std_dist\"])\n",
    "    if d.empty:\n",
    "        ax.axis(\"off\"); ax.set_title(title, fontsize=11)\n",
    "        ax.text(0.5, 0.5, \"No numeric distances.\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    parties = sorted(set(d[\"party_a\"]).union(set(d[\"party_b\"])))\n",
    "    idx = {p:i for i,p in enumerate(parties)}\n",
    "    M = np.zeros((len(parties), len(parties)), dtype=float)\n",
    "    for _, r in d.iterrows():\n",
    "        i, j = idx[r[\"party_a\"]], idx[r[\"party_b\"]]\n",
    "        M[i, j] = r[\"std_dist\"]; M[j, i] = r[\"std_dist\"]\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "\n",
    "    im = ax.imshow(M, aspect=\"auto\", vmin=vmin, vmax=vmax)\n",
    "    ax.set_xticks(range(len(parties))); ax.set_yticks(range(len(parties)))\n",
    "    ax.set_xticklabels(parties, rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(parties, fontsize=8)\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"std. centroid distance\", fontsize=8)\n",
    "    for t in cbar.ax.get_yticklabels(): t.set_fontsize(8)\n",
    "\n",
    "# ---------- One-page PDF ----------\n",
    "def build_topic_pdf(topic_title, res_meps, res_cap, res_w, pw_meps, pw_cap, pw_w, outpath):\n",
    "    log(f'  step: build PDF layout for \"{topic_title}\"')\n",
    "    ylim = _shared_ylim([res_meps, res_cap, res_w])\n",
    "    vmin, vmax = _heat_cbar_limits([pw_meps, pw_cap, pw_w])\n",
    "\n",
    "    plt.rcParams.update({\"font.size\": 10})\n",
    "    fig = plt.figure(figsize=(11.69, 8.27))\n",
    "    gs  = GridSpec(4, 3, figure=fig,\n",
    "                   height_ratios=[0.9, 3, 3, 0.6],\n",
    "                   hspace=0.75, wspace=0.6)\n",
    "\n",
    "    # Title + subtitle\n",
    "    ax_title = fig.add_subplot(gs[0, :]); ax_title.axis(\"off\")\n",
    "    ax_title.text(0.5, 0.78,\n",
    "                  f\"European Parliament Rhetorical Polarization — {topic_title}\",\n",
    "                  ha=\"center\", va=\"center\", fontsize=16, weight=\"bold\")\n",
    "    ax_title.text(0.5, 0.22,\n",
    "                  \"Line charts: CPC per year (higher = parties sound more distinct); shaded = 95% CI; \"\n",
    "                  \"hollow circles at 0% = years failing data thresholds.  \"\n",
    "                  \"Heatmaps: who is far/near in the latest valid year (larger = farther, relative to within-party variation).\",\n",
    "                  ha=\"center\", va=\"center\", fontsize=9, color=\"dimgray\")\n",
    "\n",
    "    # Time series row\n",
    "    ax_ts1 = fig.add_subplot(gs[1, 0])\n",
    "    ax_ts2 = fig.add_subplot(gs[1, 1], sharey=ax_ts1)\n",
    "    ax_ts3 = fig.add_subplot(gs[1, 2], sharey=ax_ts1)\n",
    "    plot_time_series(ax_ts1, res_meps, \"MEP-averaged (speaker-equal)\", show_legend=True,  ylim=ylim)\n",
    "    plot_time_series(ax_ts2, res_cap,  \"Speech-capped (per-MEP cap)\", show_legend=False, ylim=ylim)\n",
    "    plot_time_series(ax_ts3, res_w,    \"Speech-weighted (as heard)\",  show_legend=False, ylim=ylim)\n",
    "    for ax in (ax_ts2, ax_ts3):\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # Heatmaps row\n",
    "    ax_hm1 = fig.add_subplot(gs[2, 0])\n",
    "    ax_hm2 = fig.add_subplot(gs[2, 1])\n",
    "    ax_hm3 = fig.add_subplot(gs[2, 2])\n",
    "    plot_heatmap(ax_hm1, pw_meps, \"Pairwise — MEP-averaged\", vmin, vmax)\n",
    "    plot_heatmap(ax_hm2, pw_cap,  \"Pairwise — Speech-capped\", vmin, vmax)\n",
    "    plot_heatmap(ax_hm3, pw_w,    \"Pairwise — Speech-weighted\", vmin, vmax)\n",
    "\n",
    "    # Footnote\n",
    "    ax_foot = fig.add_subplot(gs[3, :]); ax_foot.axis(\"off\")\n",
    "    ax_foot.text(\n",
    "        0.01, 0.55,\n",
    "        \"Notes: CPC = BSS/TSS (Mehlhaff’s group-based polarization). For unweighted modes we use the small-sample adjusted CPC (CPC_adj); \"\n",
    "        \"uncertainty via speaker-cluster bootstrap. Distances standardized by within-party spread. \"\n",
    "        \"Language/topic de-meaning and one PCA keep years comparable; guardrails can yield low_n (no valid bin).\",\n",
    "        ha=\"left\", va=\"center\", fontsize=8, color=\"dimgray\"\n",
    "    )\n",
    "\n",
    "    fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    log(f\"  step: PDF saved → {outpath}\")\n",
    "\n",
    "# ---------- Small summaries ----------\n",
    "def _summarize_res(df):\n",
    "    df = _ensure_time_and_numeric(df)\n",
    "    ok, low = _split_ok_low(df)\n",
    "    info = {}\n",
    "    if not ok.empty:\n",
    "        info[\"n_bins_total\"] = int(len(df))\n",
    "        info[\"n_bins_ok\"]    = int(len(ok))\n",
    "        info[\"first_ok\"]     = pd.to_datetime(ok[\"time_bin\"]).min()\n",
    "        info[\"latest_ok\"]    = pd.to_datetime(ok[\"time_bin\"]).max()\n",
    "        info[\"eta_mean\"]     = float(ok[\"obs_bss_tss\"].mean())\n",
    "        info[\"eta_max\"]      = float(ok[\"obs_bss_tss\"].max())\n",
    "    else:\n",
    "        info[\"n_bins_total\"] = int(len(df))\n",
    "        info[\"n_bins_ok\"]    = 0\n",
    "        info[\"first_ok\"]     = None\n",
    "        info[\"latest_ok\"]    = None\n",
    "        info[\"eta_mean\"]     = None\n",
    "        info[\"eta_max\"]      = None\n",
    "    return info\n",
    "\n",
    "# ---------- Core runner for one topic (VERBOSE) ----------\n",
    "def run_one_topic(df, topic, out_dir,\n",
    "                  cap_per_speaker=5,\n",
    "                  min_speeches_per_party=20,\n",
    "                  min_unique_speakers_per_party=5,\n",
    "                  require_parties=3):\n",
    "    \"\"\"\n",
    "    topic: macro_topic string, or the special label 'ALL' for all speeches.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    pretty_name = \"All speeches\" if str(topic).upper() == \"ALL\" else topic\n",
    "    log(f'▶ topic: \"{pretty_name}\" → {out_dir}')\n",
    "    t0 = time.time()\n",
    "\n",
    "    # quick pre-count\n",
    "    if str(topic).upper() == \"ALL\":\n",
    "        pre_n = len(df)\n",
    "    else:\n",
    "        pre_n = int((df[\"macro_topic\"]==topic).sum()) if \"macro_topic\" in df.columns else None\n",
    "    if pre_n is not None:\n",
    "        log(f\"  step: filter count → {pre_n} speeches in df for this topic (before guardrails)\")\n",
    "\n",
    "    # 1) MEP-averaged\n",
    "    log(\"  step: run mode=speaker (MEP-averaged)\")\n",
    "    s = time.time()\n",
    "    res_meps, pw_meps = run_macro_series(\n",
    "        df, topic, mode=\"speaker\",\n",
    "        keep_min_speakers=0, require_parties=require_parties\n",
    "    )\n",
    "    log(f\"    done in {time.time()-s:.1f}s | rows={len(res_meps)} | pw={'ok' if pw_meps is not None else 'none'}\")\n",
    "    info = _summarize_res(res_meps); log(f\"    bins_ok={info['n_bins_ok']} latest_ok={info['latest_ok']} CPC_max={info['eta_max']}\")\n",
    "\n",
    "    # 2) Speech-capped\n",
    "    log(\"  step: run mode=speech_capped (per-MEP cap)\")\n",
    "    s = time.time()\n",
    "    res_cap, pw_cap = run_macro_series(\n",
    "        df, topic, mode=\"speech_capped\", cap_per_speaker=cap_per_speaker,\n",
    "        min_speeches_per_party=min_speeches_per_party,\n",
    "        min_unique_speakers_per_party=min_unique_speakers_per_party,\n",
    "        require_parties=require_parties\n",
    "    )\n",
    "    log(f\"    done in {time.time()-s:.1f}s | rows={len(res_cap)} | pw={'ok' if pw_cap is not None else 'none'}\")\n",
    "    info = _summarize_res(res_cap); log(f\"    bins_ok={info['n_bins_ok']} latest_ok={info['latest_ok']} CPC_max={info['eta_max']}\")\n",
    "\n",
    "    # 3) Speech-weighted\n",
    "    log(\"  step: run mode=speech_weighted (as heard)\")\n",
    "    s = time.time()\n",
    "    res_w, pw_w = run_macro_series(\n",
    "        df, topic, mode=\"speech_weighted\", weight_by=\"tokens\",\n",
    "        min_speeches_per_party=min_speeches_per_party,\n",
    "        min_unique_speakers_per_party=min_unique_speakers_per_party,\n",
    "        require_parties=require_parties\n",
    "    )\n",
    "    log(f\"    done in {time.time()-s:.1f}s | rows={len(res_w)} | pw={'ok' if pw_w is not None else 'none'}\")\n",
    "    info = _summarize_res(res_w); log(f\"    bins_ok={info['n_bins_ok']} latest_ok={info['latest_ok']} CPC_max={info['eta_max']}\")\n",
    "\n",
    "    # 4) Save CSVs\n",
    "    log(\"  step: save CSVs\")\n",
    "    res_meps.to_csv(os.path.join(out_dir, \"res_meps.csv\"), index=False)\n",
    "    res_cap.to_csv( os.path.join(out_dir, \"res_cap.csv\"),  index=False)\n",
    "    res_w.to_csv(   os.path.join(out_dir, \"res_w.csv\"),    index=False)\n",
    "    if pw_meps is not None: pw_meps.to_csv(os.path.join(out_dir, \"pw_meps.csv\"), index=False)\n",
    "    if pw_cap  is not None: pw_cap.to_csv( os.path.join(out_dir, \"pw_cap.csv\"),  index=False)\n",
    "    if pw_w    is not None: pw_w.to_csv(   os.path.join(out_dir, \"pw_w.csv\"),    index=False)\n",
    "    log(\"    CSVs saved.\")\n",
    "\n",
    "    # 5) PDF\n",
    "    pdf_path = os.path.join(out_dir, \"topic_report.pdf\")\n",
    "    build_topic_pdf(pretty_name, res_meps, res_cap, res_w, pw_meps, pw_cap, pw_w, pdf_path)\n",
    "\n",
    "    log(f'✔ topic done: \"{pretty_name}\" in {time.time()-t0:.1f}s | PDF → {pdf_path}\\n')\n",
    "\n",
    "    # return summary row\n",
    "    def _last_ok(df_):\n",
    "        v = df_[df_[\"ok\"]==True]\n",
    "        return pd.to_datetime(v[\"time_bin\"]).max() if not v.empty else pd.NaT\n",
    "    return {\n",
    "        \"topic\": pretty_name,\n",
    "        \"macro_topic\": topic,\n",
    "        \"out_dir\": out_dir,\n",
    "        \"latest_ok_meps\": _last_ok(res_meps),\n",
    "        \"latest_ok_cap\":  _last_ok(res_cap),\n",
    "        \"latest_ok_w\":    _last_ok(res_w),\n",
    "        \"pdf\": pdf_path\n",
    "    }\n",
    "\n",
    "# ---------- Topics summary based on saved CSVs ----------\n",
    "def _metrics_for_mode(res_df, base_end_year=2018):\n",
    "    if res_df is None or res_df.empty:\n",
    "        return {\n",
    "            \"base_eta\": np.nan,\n",
    "            \"peak_eta\": np.nan,\n",
    "            \"peak_year\": np.nan,\n",
    "            \"peak_z\": np.nan,\n",
    "            \"latest_eta\": np.nan,\n",
    "            \"latest_year\": np.nan,\n",
    "            \"last3_eta\": np.nan,\n",
    "            \"uplift_latest\": np.nan,\n",
    "            \"uplift_last3\": np.nan,\n",
    "            \"coverage\": 0.0,\n",
    "        }\n",
    "    df = _ensure_time_and_numeric(res_df)\n",
    "    df[\"year\"] = pd.to_datetime(df[\"time_bin\"], errors=\"coerce\").dt.year\n",
    "    ok = df[df[\"ok\"]==True].copy()\n",
    "    if ok.empty:\n",
    "        return {\n",
    "            \"base_eta\": np.nan,\n",
    "            \"peak_eta\": np.nan,\n",
    "            \"peak_year\": np.nan,\n",
    "            \"peak_z\": np.nan,\n",
    "            \"latest_eta\": np.nan,\n",
    "            \"latest_year\": np.nan,\n",
    "            \"last3_eta\": np.nan,\n",
    "            \"uplift_latest\": np.nan,\n",
    "            \"uplift_last3\": np.nan,\n",
    "            \"coverage\": 0.0,\n",
    "        }\n",
    "\n",
    "    coverage = len(ok) / len(df)\n",
    "    base = ok[ok[\"year\"] <= base_end_year]\n",
    "    base_eta = float(base[\"obs_bss_tss\"].mean()) if not base.empty else np.nan\n",
    "\n",
    "    idx_peak = ok[\"obs_bss_tss\"].idxmax()\n",
    "    peak_eta = float(ok.loc[idx_peak, \"obs_bss_tss\"])\n",
    "    peak_year = int(ok.loc[idx_peak, \"year\"])\n",
    "    peak_z = float(ok.loc[idx_peak, \"z\"])\n",
    "\n",
    "    latest_year = int(ok[\"year\"].max())\n",
    "    latest_row = ok[ok[\"year\"]==latest_year].sort_values(\"time_bin\").iloc[-1]\n",
    "    latest_eta = float(latest_row[\"obs_bss_tss\"])\n",
    "\n",
    "    years = sorted(ok[\"year\"].dropna().unique())\n",
    "    last3_years = years[-3:] if len(years) >= 3 else years\n",
    "    last3 = ok[ok[\"year\"].isin(last3_years)]\n",
    "    last3_eta = float(last3[\"obs_bss_tss\"].mean()) if not last3.empty else np.nan\n",
    "\n",
    "    def _uplift(x, base):\n",
    "        if base is None or not np.isfinite(base) or base <= 0:\n",
    "            return np.nan\n",
    "        return (x - base) / base\n",
    "\n",
    "    uplift_latest = _uplift(latest_eta, base_eta)\n",
    "    uplift_last3 = _uplift(last3_eta, base_eta)\n",
    "\n",
    "    return {\n",
    "        \"base_eta\": base_eta,\n",
    "        \"peak_eta\": peak_eta,\n",
    "        \"peak_year\": peak_year,\n",
    "        \"peak_z\": peak_z,\n",
    "        \"latest_eta\": latest_eta,\n",
    "        \"latest_year\": latest_year,\n",
    "        \"last3_eta\": last3_eta,\n",
    "        \"uplift_latest\": uplift_latest,\n",
    "        \"uplift_last3\": uplift_last3,\n",
    "        \"coverage\": coverage,\n",
    "    }\n",
    "\n",
    "def _top_pair_from_pw(pw_df):\n",
    "    if pw_df is None or pw_df.empty or \"std_dist\" not in pw_df.columns:\n",
    "        return (None, np.nan)\n",
    "    d = pw_df.copy()\n",
    "    d[\"std_dist\"] = pd.to_numeric(d[\"std_dist\"], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[\"std_dist\"])\n",
    "    if d.empty:\n",
    "        return (None, np.nan)\n",
    "    row = d.loc[d[\"std_dist\"].idxmax()]\n",
    "    pair = f\"{row['party_a']}–{row['party_b']}\"\n",
    "    return (pair, float(row[\"std_dist\"]))\n",
    "\n",
    "def build_topics_summary(base_dir=BASE_DIR, topics=None, include_all=True):\n",
    "    \"\"\"\n",
    "    Build a simple topics_summary_v6.csv using the saved res_*.csv and pw_*.csv.\n",
    "    \"\"\"\n",
    "    if topics is None:\n",
    "        topics = TOPICS\n",
    "    rows = []\n",
    "\n",
    "    if include_all:\n",
    "        topics_for_summary = [\"ALL\"] + list(topics)\n",
    "    else:\n",
    "        topics_for_summary = list(topics)\n",
    "\n",
    "    for topic in topics_for_summary:\n",
    "        slug = \"_all_speeches\" if str(topic).upper()==\"ALL\" else _slugify(topic)\n",
    "        out_dir = os.path.join(base_dir, slug)\n",
    "        pretty_name = \"All speeches\" if str(topic).upper()==\"ALL\" else topic\n",
    "\n",
    "        try:\n",
    "            res_meps = pd.read_csv(os.path.join(out_dir, \"res_meps.csv\"))\n",
    "        except Exception:\n",
    "            res_meps = None\n",
    "        try:\n",
    "            res_cap = pd.read_csv(os.path.join(out_dir, \"res_cap.csv\"))\n",
    "        except Exception:\n",
    "            res_cap = None\n",
    "        try:\n",
    "            res_w = pd.read_csv(os.path.join(out_dir, \"res_w.csv\"))\n",
    "        except Exception:\n",
    "            res_w = None\n",
    "\n",
    "        try:\n",
    "            pw_meps = pd.read_csv(os.path.join(out_dir, \"pw_meps.csv\"))\n",
    "        except Exception:\n",
    "            pw_meps = None\n",
    "        try:\n",
    "            pw_cap = pd.read_csv(os.path.join(out_dir, \"pw_cap.csv\"))\n",
    "        except Exception:\n",
    "            pw_cap = None\n",
    "        try:\n",
    "            pw_w = pd.read_csv(os.path.join(out_dir, \"pw_w.csv\"))\n",
    "        except Exception:\n",
    "            pw_w = None\n",
    "\n",
    "        m_meps = _metrics_for_mode(res_meps)\n",
    "        m_cap  = _metrics_for_mode(res_cap)\n",
    "        m_w    = _metrics_for_mode(res_w)\n",
    "\n",
    "        pair_meps, dist_meps = _top_pair_from_pw(pw_meps)\n",
    "        pair_cap,  dist_cap  = _top_pair_from_pw(pw_cap)\n",
    "        pair_w,    dist_w    = _top_pair_from_pw(pw_w)\n",
    "\n",
    "        rows.append({\n",
    "            \"topic\": pretty_name,\n",
    "            \"macro_topic\": topic,\n",
    "            # MEP-avg\n",
    "            \"m_base_eta\": m_meps[\"base_eta\"],\n",
    "            \"m_peak_eta\": m_meps[\"peak_eta\"],\n",
    "            \"m_peak_year\": m_meps[\"peak_year\"],\n",
    "            \"m_peak_z\": m_meps[\"peak_z\"],\n",
    "            \"m_latest_eta\": m_meps[\"latest_eta\"],\n",
    "            \"m_latest_year\": m_meps[\"latest_year\"],\n",
    "            \"m_last3_eta\": m_meps[\"last3_eta\"],\n",
    "            \"m_uplift_latest\": m_meps[\"uplift_latest\"],\n",
    "            \"m_uplift_last3\": m_meps[\"uplift_last3\"],\n",
    "            \"m_coverage\": m_meps[\"coverage\"],\n",
    "            \"m_top_pair\": pair_meps,\n",
    "            \"m_top_dist\": dist_meps,\n",
    "            # capped\n",
    "            \"c_base_eta\": m_cap[\"base_eta\"],\n",
    "            \"c_peak_eta\": m_cap[\"peak_eta\"],\n",
    "            \"c_peak_year\": m_cap[\"peak_year\"],\n",
    "            \"c_peak_z\": m_cap[\"peak_z\"],\n",
    "            \"c_latest_eta\": m_cap[\"latest_eta\"],\n",
    "            \"c_latest_year\": m_cap[\"latest_year\"],\n",
    "            \"c_last3_eta\": m_cap[\"last3_eta\"],\n",
    "            \"c_uplift_latest\": m_cap[\"uplift_latest\"],\n",
    "            \"c_uplift_last3\": m_cap[\"uplift_last3\"],\n",
    "            \"c_coverage\": m_cap[\"coverage\"],\n",
    "            \"c_top_pair\": pair_cap,\n",
    "            \"c_top_dist\": dist_cap,\n",
    "            # weighted\n",
    "            \"w_base_eta\": m_w[\"base_eta\"],\n",
    "            \"w_peak_eta\": m_w[\"peak_eta\"],\n",
    "            \"w_peak_year\": m_w[\"peak_year\"],\n",
    "            \"w_peak_z\": m_w[\"peak_z\"],\n",
    "            \"w_latest_eta\": m_w[\"latest_eta\"],\n",
    "            \"w_latest_year\": m_w[\"latest_year\"],\n",
    "            \"w_last3_eta\": m_w[\"last3_eta\"],\n",
    "            \"w_uplift_latest\": m_w[\"uplift_latest\"],\n",
    "            \"w_uplift_last3\": m_w[\"uplift_last3\"],\n",
    "            \"w_coverage\": m_w[\"coverage\"],\n",
    "            \"w_top_pair\": pair_w,\n",
    "            \"w_top_dist\": dist_w,\n",
    "        })\n",
    "\n",
    "    ts_df = pd.DataFrame(rows)\n",
    "    out_path = os.path.join(base_dir, \"topics_summary_v6.csv\")\n",
    "    ts_df.to_csv(out_path, index=False)\n",
    "    log(f\"Topics summary saved → {out_path}\")\n",
    "    return ts_df\n",
    "\n",
    "# ---------- Batch all topics (VERBOSE) ----------\n",
    "def run_all_topics(df, topics=TOPICS, base_dir=BASE_DIR, include_all=True):\n",
    "    log(f\"Batch start — {len(topics)} topics → base folder: {base_dir}\")\n",
    "    summaries = []\n",
    "\n",
    "    # ALL-speeches slice first (optional)\n",
    "    if include_all:\n",
    "        all_dir = os.path.join(base_dir, \"_all_speeches\")\n",
    "        try:\n",
    "            summary_all = run_one_topic(df, \"ALL\", all_dir)\n",
    "            summaries.append(summary_all)\n",
    "        except Exception as e:\n",
    "            os.makedirs(all_dir, exist_ok=True)\n",
    "            msg = f\"{type(e).__name__}: {e}\"\n",
    "            log(f\"✖ ERROR topic: ALL → {msg}\")\n",
    "            with open(os.path.join(all_dir, \"ERROR.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"ALL\\n{msg}\\n\")\n",
    "            summaries.append({\n",
    "                \"topic\": \"All speeches\", \"macro_topic\": \"ALL\",\n",
    "                \"out_dir\": all_dir, \"latest_ok_meps\": pd.NaT,\n",
    "                \"latest_ok_cap\": pd.NaT, \"latest_ok_w\": pd.NaT,\n",
    "                \"pdf\": os.path.join(all_dir, \"topic_report.pdf\"), \"error\": msg\n",
    "            })\n",
    "\n",
    "    # Macro topics\n",
    "    for topic in _progress(topics, \"Processing topics\"):\n",
    "        slug = _slugify(topic)\n",
    "        out_dir = os.path.join(base_dir, slug)\n",
    "        try:\n",
    "            summary = run_one_topic(df, topic, out_dir)\n",
    "            summaries.append(summary)\n",
    "        except Exception as e:\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            msg = f\"{type(e).__name__}: {e}\"\n",
    "            log(f\"✖ ERROR topic: {topic} → {msg}\")\n",
    "            with open(os.path.join(out_dir, \"ERROR.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{topic}\\n{msg}\\n\")\n",
    "            summaries.append({\n",
    "                \"topic\": topic, \"macro_topic\": topic,\n",
    "                \"out_dir\": out_dir, \"latest_ok_meps\": pd.NaT,\n",
    "                \"latest_ok_cap\": pd.NaT, \"latest_ok_w\": pd.NaT,\n",
    "                \"pdf\": os.path.join(out_dir, \"topic_report.pdf\"), \"error\": msg\n",
    "            })\n",
    "\n",
    "    sm_df = pd.DataFrame(summaries)\n",
    "    out_summary = os.path.join(base_dir, \"batch_summary.csv\")\n",
    "    sm_df.to_csv(out_summary, index=False)\n",
    "    log(f\"Batch finished → {out_summary}\")\n",
    "\n",
    "    # Build topics_summary_v6.csv\n",
    "    _ = build_topics_summary(base_dir=base_dir, topics=topics, include_all=include_all)\n",
    "\n",
    "    return sm_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73531f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- helper: does this topic look complete? ----------\n",
    "def _topic_is_complete(out_dir):\n",
    "    \"\"\"\n",
    "    A topic is considered 'done' if the three result CSVs and the PDF exist\n",
    "    and are non-empty. If any are missing or zero-byte, we will re-run it.\n",
    "    \"\"\"\n",
    "    required_files = [\n",
    "        os.path.join(out_dir, \"res_meps.csv\"),\n",
    "        os.path.join(out_dir, \"res_cap.csv\"),\n",
    "        os.path.join(out_dir, \"res_w.csv\"),\n",
    "        os.path.join(out_dir, \"topic_report.pdf\"),\n",
    "    ]\n",
    "    for f in required_files:\n",
    "        if not os.path.exists(f):\n",
    "            return False\n",
    "        try:\n",
    "            if os.path.getsize(f) <= 0:\n",
    "                return False\n",
    "        except OSError:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def _last_ok_from_res(path):\n",
    "    \"\"\"\n",
    "    Read a res_*.csv and return the latest time_bin with ok==True, or NaT.\n",
    "    Used only to populate the summary_df row on resume.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "    if \"ok\" not in df.columns or \"time_bin\" not in df.columns:\n",
    "        return pd.NaT\n",
    "    v = df[df[\"ok\"] == True].copy()\n",
    "    if v.empty:\n",
    "        return pd.NaT\n",
    "    v[\"time_bin\"] = pd.to_datetime(v[\"time_bin\"], errors=\"coerce\")\n",
    "    return v[\"time_bin\"].max()\n",
    "\n",
    "# ---------- NEW: resume-aware batch runner ----------\n",
    "def run_all_topics_resume(df, topics=TOPICS, base_dir=BASE_DIR, include_all=True):\n",
    "    \"\"\"\n",
    "    Resume-aware version of run_all_topics:\n",
    "    - SKIPS topics (and ALL-speeches) whose outputs already exist.\n",
    "    - Re-runs only incomplete topics.\n",
    "    - Rebuilds topics_summary_v6.csv at the end.\n",
    "    \"\"\"\n",
    "    log(f\"Resume batch start — {len(topics)} topics → base folder: {base_dir}\")\n",
    "    summaries = []\n",
    "\n",
    "    # ---- ALL-speeches slice first (optional) ----\n",
    "    if include_all:\n",
    "        all_dir = os.path.join(base_dir, \"_all_speeches\")\n",
    "        pretty_name = \"All speeches\"\n",
    "        if _topic_is_complete(all_dir):\n",
    "            log(f'▶ SKIP \"All speeches\" — existing outputs found in {all_dir}')\n",
    "            res_meps_path = os.path.join(all_dir, \"res_meps.csv\")\n",
    "            summaries.append({\n",
    "                \"topic\": pretty_name,\n",
    "                \"macro_topic\": \"ALL\",\n",
    "                \"out_dir\": all_dir,\n",
    "                \"latest_ok_meps\": _last_ok_from_res(res_meps_path),\n",
    "                \"latest_ok_cap\":  _last_ok_from_res(os.path.join(all_dir, \"res_cap.csv\")),\n",
    "                \"latest_ok_w\":    _last_ok_from_res(os.path.join(all_dir, \"res_w.csv\")),\n",
    "                \"pdf\": os.path.join(all_dir, \"topic_report.pdf\")\n",
    "            })\n",
    "        else:\n",
    "            log(f'▶ RESUME \"All speeches\" — outputs missing/incomplete, re-running')\n",
    "            try:\n",
    "                os.makedirs(all_dir, exist_ok=True)\n",
    "                summary_all = run_one_topic(df, \"ALL\", all_dir)\n",
    "                summaries.append(summary_all)\n",
    "            except Exception as e:\n",
    "                msg = f\"{type(e).__name__}: {e}\"\n",
    "                log(f\"✖ ERROR topic: ALL → {msg}\")\n",
    "                with open(os.path.join(all_dir, \"ERROR.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(f\"ALL\\n{msg}\\n\")\n",
    "                summaries.append({\n",
    "                    \"topic\": pretty_name, \"macro_topic\": \"ALL\",\n",
    "                    \"out_dir\": all_dir, \"latest_ok_meps\": pd.NaT,\n",
    "                    \"latest_ok_cap\": pd.NaT, \"latest_ok_w\": pd.NaT,\n",
    "                    \"pdf\": os.path.join(all_dir, \"topic_report.pdf\"), \"error\": msg\n",
    "                })\n",
    "\n",
    "    # ---- Macro topics ----\n",
    "    for topic in _progress(topics, \"Processing topics (resume)\"):\n",
    "        slug = _slugify(topic)\n",
    "        out_dir = os.path.join(base_dir, slug)\n",
    "        pretty_name = topic\n",
    "\n",
    "        if _topic_is_complete(out_dir):\n",
    "            log(f'▶ SKIP \"{pretty_name}\" — existing outputs found in {out_dir}')\n",
    "            summaries.append({\n",
    "                \"topic\": pretty_name,\n",
    "                \"macro_topic\": topic,\n",
    "                \"out_dir\": out_dir,\n",
    "                \"latest_ok_meps\": _last_ok_from_res(os.path.join(out_dir, \"res_meps.csv\")),\n",
    "                \"latest_ok_cap\":  _last_ok_from_res(os.path.join(out_dir, \"res_cap.csv\")),\n",
    "                \"latest_ok_w\":    _last_ok_from_res(os.path.join(out_dir, \"res_w.csv\")),\n",
    "                \"pdf\": os.path.join(out_dir, \"topic_report.pdf\")\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        log(f'▶ RESUME \"{pretty_name}\" — outputs missing/incomplete, re-running')\n",
    "        try:\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            summary = run_one_topic(df, topic, out_dir)\n",
    "            summaries.append(summary)\n",
    "        except Exception as e:\n",
    "            msg = f\"{type(e).__name__}: {e}\"\n",
    "            log(f\"✖ ERROR topic: {topic} → {msg}\")\n",
    "            with open(os.path.join(out_dir, \"ERROR.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{topic}\\n{msg}\\n\")\n",
    "            summaries.append({\n",
    "                \"topic\": pretty_name, \"macro_topic\": topic,\n",
    "                \"out_dir\": out_dir, \"latest_ok_meps\": pd.NaT,\n",
    "                \"latest_ok_cap\": pd.NaT, \"latest_ok_w\": pd.NaT,\n",
    "                \"pdf\": os.path.join(out_dir, \"topic_report.pdf\"), \"error\": msg\n",
    "            })\n",
    "\n",
    "    sm_df = pd.DataFrame(summaries)\n",
    "    out_summary = os.path.join(base_dir, \"batch_summary_resume.csv\")\n",
    "    sm_df.to_csv(out_summary, index=False)\n",
    "    log(f\"Resume batch finished → {out_summary}\")\n",
    "\n",
    "    # Rebuild topics_summary_v6.csv from whatever is now in reports_v6/\n",
    "    _ = build_topics_summary(base_dir=base_dir, topics=topics, include_all=include_all)\n",
    "\n",
    "    return sm_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6345cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:59] Resume batch start — 30 topics → base folder: reports_v6\n",
      "[11:27:59] ▶ SKIP \"All speeches\" — existing outputs found in reports_v6/_all_speeches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume):   0%|                                            | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:59] ▶ SKIP \"Agriculture & fisheries\" — existing outputs found in reports_v6/agriculture-and-fisheries\n",
      "[11:27:59] ▶ SKIP \"Climate, environment & biodiversity\" — existing outputs found in reports_v6/climate-environment-and-biodiversity\n",
      "[11:27:59] ▶ SKIP \"Development & humanitarian aid\" — existing outputs found in reports_v6/development-and-humanitarian-aid\n",
      "[11:27:59] ▶ SKIP \"Digital policy & data protection\" — existing outputs found in reports_v6/digital-policy-and-data-protection\n",
      "[11:27:59] ▶ SKIP \"EU budget & MFF\" — existing outputs found in reports_v6/eu-budget-and-mff\n",
      "[11:27:59] ▶ SKIP \"Economy & industrial policy\" — existing outputs found in reports_v6/economy-and-industrial-policy\n",
      "[11:27:59] ▶ SKIP \"Education, culture & sport\" — existing outputs found in reports_v6/education-culture-and-sport\n",
      "[11:27:59] ▶ SKIP \"Energy & energy security\" — existing outputs found in reports_v6/energy-and-energy-security\n",
      "[11:27:59] ▶ SKIP \"Enlargement & neighbourhood policy\" — existing outputs found in reports_v6/enlargement-and-neighbourhood-policy\n",
      "[11:27:59] ▶ SKIP \"Foreign policy — Americas\" — existing outputs found in reports_v6/foreign-policy-americas\n",
      "[11:27:59] ▶ SKIP \"Foreign policy — Asia-Pacific\" — existing outputs found in reports_v6/foreign-policy-asia-pacific\n",
      "[11:27:59] ▶ SKIP \"Foreign policy — Europe & Eastern Neighbourhood\" — existing outputs found in reports_v6/foreign-policy-europe-and-eastern-neighbourhood\n",
      "[11:27:59] ▶ SKIP \"Foreign policy — Middle East & North Africa\" — existing outputs found in reports_v6/foreign-policy-middle-east-and-north-africa\n",
      "[11:27:59] ▶ SKIP \"Foreign policy — Sub-Saharan Africa\" — existing outputs found in reports_v6/foreign-policy-sub-saharan-africa\n",
      "[11:27:59] ▶ SKIP \"Health\" — existing outputs found in reports_v6/health\n",
      "[11:27:59] ▶ SKIP \"Institutional affairs & governance\" — existing outputs found in reports_v6/institutional-affairs-and-governance\n",
      "[11:27:59] ▶ SKIP \"Justice, security & policing\" — existing outputs found in reports_v6/justice-security-and-policing\n",
      "[11:27:59] ▶ SKIP \"Media, information & disinformation\" — existing outputs found in reports_v6/media-information-and-disinformation\n",
      "[11:27:59] ▶ SKIP \"Migration & asylum\" — existing outputs found in reports_v6/migration-and-asylum\n",
      "[11:27:59] ▶ SKIP \"Monetary & financial stability\" — existing outputs found in reports_v6/monetary-and-financial-stability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume):  67%|██████████████████████▋           | 20/30 [00:00<00:00, 195.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:59] ▶ SKIP \"Procedural & Parliamentary business\" — existing outputs found in reports_v6/procedural-and-parliamentary-business\n",
      "[11:27:59] ▶ SKIP \"Research, innovation & space\" — existing outputs found in reports_v6/research-innovation-and-space\n",
      "[11:27:59] ▶ SKIP \"Rule of law & fundamental rights\" — existing outputs found in reports_v6/rule-of-law-and-fundamental-rights\n",
      "[11:27:59] ▶ SKIP \"Security & defence\" — existing outputs found in reports_v6/security-and-defence\n",
      "[11:27:59] ▶ SKIP \"Security & policing\" — existing outputs found in reports_v6/security-and-policing\n",
      "[11:27:59] ▶ SKIP \"Single market, competition & consumer protection\" — existing outputs found in reports_v6/single-market-competition-and-consumer-protection\n",
      "[11:27:59] ▶ RESUME \"Social policy & employment\" — outputs missing/incomplete, re-running\n",
      "[11:27:59] ▶ topic: \"Social policy & employment\" → reports_v6/social-policy-and-employment\n",
      "[11:27:59]   step: filter count → 7525 speeches in df for this topic (before guardrails)\n",
      "[11:27:59]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232ecf2ff6ff44b0baea340c0c3f1471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume):  67%|██████████████████████▋           | 20/30 [00:20<00:00, 195.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:33:45]     done in 345.9s | rows=10 | pw=ok\n",
      "[11:33:45]     bins_ok=3 latest_ok=2023-01-01 00:00:00 CPC_max=0.04620823204813713\n",
      "[11:33:45]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db41d8163ee04bd1a7611fbe91654d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:05]     done in 319.5s | rows=10 | pw=ok\n",
      "[11:39:05]     bins_ok=10 latest_ok=2024-01-01 00:00:00 CPC_max=0.041418160839152514\n",
      "[11:39:05]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89267a026f841ed805fd882a2771657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:25]     done in 380.4s | rows=10 | pw=ok\n",
      "[11:45:25]     bins_ok=10 latest_ok=2024-01-01 00:00:00 CPC_max=0.04703684753298065\n",
      "[11:45:25]   step: save CSVs\n",
      "[11:45:25]     CSVs saved.\n",
      "[11:45:25]   step: build PDF layout for \"Social policy & employment\"\n",
      "[11:45:27]   step: PDF saved → reports_v6/social-policy-and-employment/topic_report.pdf\n",
      "[11:45:27] ✔ topic done: \"Social policy & employment\" in 1047.6s | PDF → reports_v6/social-policy-and-employment/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume):  90%|███████████████████████████████▌   | 27/30 [17:27<02:29, 49.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:27] ▶ RESUME \"Taxation & anti-money laundering\" — outputs missing/incomplete, re-running\n",
      "[11:45:27] ▶ topic: \"Taxation & anti-money laundering\" → reports_v6/taxation-and-anti-money-laundering\n",
      "[11:45:27]   step: filter count → 0 speeches in df for this topic (before guardrails)\n",
      "[11:45:27]   step: run mode=speaker (MEP-averaged)\n",
      "[11:45:27]     done in 0.0s | rows=0 | pw=none\n",
      "[11:45:27]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[11:45:27]   step: run mode=speech_capped (per-MEP cap)\n",
      "[11:45:27]     done in 0.0s | rows=0 | pw=none\n",
      "[11:45:27]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[11:45:27]   step: run mode=speech_weighted (as heard)\n",
      "[11:45:27]     done in 0.0s | rows=0 | pw=none\n",
      "[11:45:27]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[11:45:27]   step: save CSVs\n",
      "[11:45:27]     CSVs saved.\n",
      "[11:45:27]   step: build PDF layout for \"Taxation & anti-money laundering\"\n",
      "[11:45:27]   step: PDF saved → reports_v6/taxation-and-anti-money-laundering/topic_report.pdf\n",
      "[11:45:27] ✔ topic done: \"Taxation & anti-money laundering\" in 0.2s | PDF → reports_v6/taxation-and-anti-money-laundering/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume):  93%|████████████████████████████████▋  | 28/30 [17:27<01:33, 46.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:27] ▶ RESUME \"Trade & globalization\" — outputs missing/incomplete, re-running\n",
      "[11:45:27] ▶ topic: \"Trade & globalization\" → reports_v6/trade-and-globalization\n",
      "[11:45:27]   step: filter count → 5979 speeches in df for this topic (before guardrails)\n",
      "[11:45:27]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02524dffd9b1499cbdff44658eb5b686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume):  93%|████████████████████████████████▋  | 28/30 [17:41<01:33, 46.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:34]     done in 307.3s | rows=11 | pw=none\n",
      "[11:50:34]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[11:50:34]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874eac4e5ab342069158e71a8b9d17ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:55:44]     done in 310.0s | rows=11 | pw=ok\n",
      "[11:55:44]     bins_ok=10 latest_ok=2025-01-01 00:00:00 CPC_max=0.038201171587525735\n",
      "[11:55:44]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6827aaa87000416ea619353dbe620d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:32]     done in 287.7s | rows=11 | pw=ok\n",
      "[12:00:32]     bins_ok=10 latest_ok=2025-01-01 00:00:00 CPC_max=0.041836972641064424\n",
      "[12:00:32]   step: save CSVs\n",
      "[12:00:32]     CSVs saved.\n",
      "[12:00:32]   step: build PDF layout for \"Trade & globalization\"\n",
      "[12:00:32]   step: PDF saved → reports_v6/trade-and-globalization/topic_report.pdf\n",
      "[12:00:32] ✔ topic done: \"Trade & globalization\" in 905.6s | PDF → reports_v6/trade-and-globalization/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume):  97%|████████████████████████████████▊ | 29/30 [32:33<01:58, 118.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:00:32] ▶ RESUME \"Transport & mobility\" — outputs missing/incomplete, re-running\n",
      "[12:00:32] ▶ topic: \"Transport & mobility\" → reports_v6/transport-and-mobility\n",
      "[12:00:32]   step: filter count → 2769 speeches in df for this topic (before guardrails)\n",
      "[12:00:32]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1262538d31a487db65d2369b671c2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:05:33]     done in 300.4s | rows=10 | pw=none\n",
      "[12:05:33]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[12:05:33]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1228253e294047b14abeb875e96600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:21]     done in 288.2s | rows=10 | pw=ok\n",
      "[12:10:21]     bins_ok=5 latest_ok=2019-01-01 00:00:00 CPC_max=0.022026286748800365\n",
      "[12:10:21]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9706ac09d3044f22820ba0858e53e879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:41]     done in 199.4s | rows=10 | pw=ok\n",
      "[12:13:41]     bins_ok=5 latest_ok=2019-01-01 00:00:00 CPC_max=0.05495741967304367\n",
      "[12:13:41]   step: save CSVs\n",
      "[12:13:41]     CSVs saved.\n",
      "[12:13:41]   step: build PDF layout for \"Transport & mobility\"\n",
      "[12:13:41]   step: PDF saved → reports_v6/transport-and-mobility/topic_report.pdf\n",
      "[12:13:41] ✔ topic done: \"Transport & mobility\" in 788.8s | PDF → reports_v6/transport-and-mobility/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics (resume): 100%|███████████████████████████████████| 30/30 [45:42<00:00, 91.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:41] Resume batch finished → reports_v6/batch_summary_resume.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:42] Topics summary saved → reports_v6/topics_summary_v6.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- CALL THIS instead of run_all_topics(df) ----------\n",
    "summary_df = run_all_topics_resume(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c0c4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:19:44] Batch start — 30 topics → base folder: reports_v6\n",
      "[20:19:44] ▶ topic: \"All speeches\" → reports_v6/_all_speeches\n",
      "[20:19:44]   step: filter count → 163079 speeches in df for this topic (before guardrails)\n",
      "[20:19:44]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5605d1d2332e41cbaa4d6da1e16d45e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:09:10]     done in 2965.4s | rows=11 | pw=ok\n",
      "[21:09:10]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.04029521102753136\n",
      "[21:09:10]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de6941131d84372b21d006d23985648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:19:11]     done in 4201.5s | rows=11 | pw=ok\n",
      "[22:19:11]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=-0.22342949501500553\n",
      "[22:19:11]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b992418347134a52a185c9a36d2be579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:58:46]     done in 2374.6s | rows=11 | pw=ok\n",
      "[22:58:46]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.010345831829924676\n",
      "[22:58:46]   step: save CSVs\n",
      "[22:58:46]     CSVs saved.\n",
      "[22:58:46]   step: build PDF layout for \"All speeches\"\n",
      "[22:58:47]   step: PDF saved → reports_v6/_all_speeches/topic_report.pdf\n",
      "[22:58:47] ✔ topic done: \"All speeches\" in 9542.4s | PDF → reports_v6/_all_speeches/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   0%|                                                     | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:58:47] ▶ topic: \"Agriculture & fisheries\" → reports_v6/agriculture-and-fisheries\n",
      "[22:58:47]   step: filter count → 5505 speeches in df for this topic (before guardrails)\n",
      "[22:58:47]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43964c2f5bf34413bfbc8b6a776cf2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:00:18]     done in 91.2s | rows=11 | pw=ok\n",
      "[23:00:18]     bins_ok=2 latest_ok=2024-01-01 00:00:00 CPC_max=0.053718635337507536\n",
      "[23:00:18]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502243c9cde74eb9a511471cd981629c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:02:10]     done in 111.8s | rows=11 | pw=ok\n",
      "[23:02:10]     bins_ok=10 latest_ok=2024-01-01 00:00:00 CPC_max=0.040072851550602966\n",
      "[23:02:10]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bb492ad5ac48599e5b707a35eb0561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:04:01]     done in 111.5s | rows=11 | pw=ok\n",
      "[23:04:01]     bins_ok=10 latest_ok=2024-01-01 00:00:00 CPC_max=0.04018157745738253\n",
      "[23:04:01]   step: save CSVs\n",
      "[23:04:01]     CSVs saved.\n",
      "[23:04:01]   step: build PDF layout for \"Agriculture & fisheries\"\n",
      "[23:04:02]   step: PDF saved → reports_v6/agriculture-and-fisheries/topic_report.pdf\n",
      "[23:04:02] ✔ topic done: \"Agriculture & fisheries\" in 315.1s | PDF → reports_v6/agriculture-and-fisheries/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   3%|█▍                                        | 1/30 [05:15<2:32:16, 315.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:04:02] ▶ topic: \"Climate, environment & biodiversity\" → reports_v6/climate-environment-and-biodiversity\n",
      "[23:04:02]   step: filter count → 9654 speeches in df for this topic (before guardrails)\n",
      "[23:04:02]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b628204b7c1446b5b6bbf8bd49114cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:06:37]     done in 155.4s | rows=11 | pw=ok\n",
      "[23:06:37]     bins_ok=3 latest_ok=2023-01-01 00:00:00 CPC_max=0.03872135353547916\n",
      "[23:06:37]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f2f7890b2942069caf256da042644c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:09:43]     done in 185.5s | rows=11 | pw=ok\n",
      "[23:09:43]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.0348974593595183\n",
      "[23:09:43]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c0d754182c42eb88ec5784626b6748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:48]     done in 184.8s | rows=11 | pw=ok\n",
      "[23:12:48]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.03463035592939664\n",
      "[23:12:48]   step: save CSVs\n",
      "[23:12:48]     CSVs saved.\n",
      "[23:12:48]   step: build PDF layout for \"Climate, environment & biodiversity\"\n",
      "[23:12:48]   step: PDF saved → reports_v6/climate-environment-and-biodiversity/topic_report.pdf\n",
      "[23:12:48] ✔ topic done: \"Climate, environment & biodiversity\" in 526.2s | PDF → reports_v6/climate-environment-and-biodiversity/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   7%|██▊                                       | 2/30 [14:01<3:24:58, 439.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:48] ▶ topic: \"Development & humanitarian aid\" → reports_v6/development-and-humanitarian-aid\n",
      "[23:12:48]   step: filter count → 3771 speeches in df for this topic (before guardrails)\n",
      "[23:12:48]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35897a265aff48e3b58f5a62fb481043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:13:56]     done in 68.0s | rows=11 | pw=ok\n",
      "[23:13:56]     bins_ok=1 latest_ok=2023-01-01 00:00:00 CPC_max=0.04871206791435968\n",
      "[23:13:56]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894c8de3f811416c9f55c8d391d431ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:15:13]     done in 77.4s | rows=11 | pw=ok\n",
      "[23:15:13]     bins_ok=8 latest_ok=2023-01-01 00:00:00 CPC_max=0.04120650835584948\n",
      "[23:15:13]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c3315e746c42eda31cf2a20f4dd24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:32]     done in 78.5s | rows=11 | pw=ok\n",
      "[23:16:32]     bins_ok=8 latest_ok=2023-01-01 00:00:00 CPC_max=0.04749766052454758\n",
      "[23:16:32]   step: save CSVs\n",
      "[23:16:32]     CSVs saved.\n",
      "[23:16:32]   step: build PDF layout for \"Development & humanitarian aid\"\n",
      "[23:16:33]   step: PDF saved → reports_v6/development-and-humanitarian-aid/topic_report.pdf\n",
      "[23:16:33] ✔ topic done: \"Development & humanitarian aid\" in 224.4s | PDF → reports_v6/development-and-humanitarian-aid/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  10%|████▏                                     | 3/30 [17:45<2:33:31, 341.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:33] ▶ topic: \"Digital policy & data protection\" → reports_v6/digital-policy-and-data-protection\n",
      "[23:16:33]   step: filter count → 4735 speeches in df for this topic (before guardrails)\n",
      "[23:16:33]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5885a8eb4749f1a9b2b6d42a26006d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:54]     done in 81.5s | rows=11 | pw=ok\n",
      "[23:17:54]     bins_ok=2 latest_ok=2025-01-01 00:00:00 CPC_max=0.03520844333003744\n",
      "[23:17:54]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519f2426a9c342ff832c4580d3123248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:29]     done in 95.2s | rows=11 | pw=ok\n",
      "[23:19:29]     bins_ok=8 latest_ok=2025-01-01 00:00:00 CPC_max=0.021086207013183644\n",
      "[23:19:29]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3650edd4315b41b5aefcc8cdc6a690f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:07]     done in 98.1s | rows=11 | pw=ok\n",
      "[23:21:07]     bins_ok=8 latest_ok=2025-01-01 00:00:00 CPC_max=0.10350981499545676\n",
      "[23:21:07]   step: save CSVs\n",
      "[23:21:07]     CSVs saved.\n",
      "[23:21:07]   step: build PDF layout for \"Digital policy & data protection\"\n",
      "[23:21:08]   step: PDF saved → reports_v6/digital-policy-and-data-protection/topic_report.pdf\n",
      "[23:21:08] ✔ topic done: \"Digital policy & data protection\" in 275.4s | PDF → reports_v6/digital-policy-and-data-protection/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  13%|█████▌                                    | 4/30 [22:21<2:16:35, 315.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:21:08] ▶ topic: \"EU budget & MFF\" → reports_v6/eu-budget-and-mff\n",
      "[23:21:08]   step: filter count → 6868 speeches in df for this topic (before guardrails)\n",
      "[23:21:08]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2025c14120c4169be448a8a072ae82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:22:58]     done in 110.1s | rows=11 | pw=ok\n",
      "[23:22:58]     bins_ok=2 latest_ok=2022-01-01 00:00:00 CPC_max=0.041946279600748634\n",
      "[23:22:58]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0523094b283c459481f380c6dd95f6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:25:06]     done in 128.0s | rows=11 | pw=ok\n",
      "[23:25:06]     bins_ok=10 latest_ok=2025-01-01 00:00:00 CPC_max=0.029884687025901153\n",
      "[23:25:06]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dd69e240a8498b8e9acc741923623b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:15]     done in 129.2s | rows=11 | pw=ok\n",
      "[23:27:15]     bins_ok=10 latest_ok=2025-01-01 00:00:00 CPC_max=0.03443085650113968\n",
      "[23:27:15]   step: save CSVs\n",
      "[23:27:15]     CSVs saved.\n",
      "[23:27:15]   step: build PDF layout for \"EU budget & MFF\"\n",
      "[23:27:16]   step: PDF saved → reports_v6/eu-budget-and-mff/topic_report.pdf\n",
      "[23:27:16] ✔ topic done: \"EU budget & MFF\" in 368.0s | PDF → reports_v6/eu-budget-and-mff/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  17%|███████                                   | 5/30 [28:29<2:19:15, 334.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:16] ▶ topic: \"Economy & industrial policy\" → reports_v6/economy-and-industrial-policy\n",
      "[23:27:16]   step: filter count → 4939 speeches in df for this topic (before guardrails)\n",
      "[23:27:16]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35a2a51d8fb4582b99a9af4d00dcaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:28:40]     done in 84.0s | rows=11 | pw=ok\n",
      "[23:28:40]     bins_ok=1 latest_ok=2023-01-01 00:00:00 CPC_max=0.038428952077089594\n",
      "[23:28:40]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550f3221a35d4b2b9503c14ec2b2802b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:20]     done in 99.8s | rows=11 | pw=ok\n",
      "[23:30:20]     bins_ok=8 latest_ok=2024-01-01 00:00:00 CPC_max=0.03363367484027276\n",
      "[23:30:20]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e82aea7b66240528e4a6c10dbe3dbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:59]     done in 99.1s | rows=11 | pw=ok\n",
      "[23:31:59]     bins_ok=8 latest_ok=2024-01-01 00:00:00 CPC_max=0.044274473127485614\n",
      "[23:31:59]   step: save CSVs\n",
      "[23:31:59]     CSVs saved.\n",
      "[23:31:59]   step: build PDF layout for \"Economy & industrial policy\"\n",
      "[23:32:00]   step: PDF saved → reports_v6/economy-and-industrial-policy/topic_report.pdf\n",
      "[23:32:00] ✔ topic done: \"Economy & industrial policy\" in 283.9s | PDF → reports_v6/economy-and-industrial-policy/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  20%|████████▍                                 | 6/30 [33:12<2:06:50, 317.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:00] ▶ topic: \"Education, culture & sport\" → reports_v6/education-culture-and-sport\n",
      "[23:32:00]   step: filter count → 2705 speeches in df for this topic (before guardrails)\n",
      "[23:32:00]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3060edac277346298c95424d2fa48927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:47]     done in 47.3s | rows=11 | pw=none\n",
      "[23:32:47]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[23:32:47]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f9fed932a34200850ec18c5ea8e3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:33:40]     done in 52.4s | rows=11 | pw=ok\n",
      "[23:33:40]     bins_ok=5 latest_ok=2021-01-01 00:00:00 CPC_max=0.02498099652400391\n",
      "[23:33:40]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41296f0e18d490099d5cd2877042228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:34]     done in 54.9s | rows=11 | pw=ok\n",
      "[23:34:34]     bins_ok=6 latest_ok=2021-01-01 00:00:00 CPC_max=0.04381369997675613\n",
      "[23:34:34]   step: save CSVs\n",
      "[23:34:34]     CSVs saved.\n",
      "[23:34:34]   step: build PDF layout for \"Education, culture & sport\"\n",
      "[23:34:35]   step: PDF saved → reports_v6/education-culture-and-sport/topic_report.pdf\n",
      "[23:34:35] ✔ topic done: \"Education, culture & sport\" in 155.0s | PDF → reports_v6/education-culture-and-sport/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  23%|█████████▊                                | 7/30 [35:47<1:41:14, 264.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:35] ▶ topic: \"Energy & energy security\" → reports_v6/energy-and-energy-security\n",
      "[23:34:35]   step: filter count → 4493 speeches in df for this topic (before guardrails)\n",
      "[23:34:35]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaad6360a5f4fcb80085ec08adb868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:58]     done in 82.8s | rows=11 | pw=ok\n",
      "[23:35:58]     bins_ok=2 latest_ok=2023-01-01 00:00:00 CPC_max=0.04270453002888198\n",
      "[23:35:58]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8674b18ce643d488dd836c449493db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:37:30]     done in 92.6s | rows=11 | pw=ok\n",
      "[23:37:30]     bins_ok=8 latest_ok=2025-01-01 00:00:00 CPC_max=0.035881773470076914\n",
      "[23:37:30]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198951f8254e48cf90f3c1544a96e41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:02]     done in 91.7s | rows=11 | pw=ok\n",
      "[23:39:02]     bins_ok=8 latest_ok=2025-01-01 00:00:00 CPC_max=0.04856699910393851\n",
      "[23:39:02]   step: save CSVs\n",
      "[23:39:02]     CSVs saved.\n",
      "[23:39:02]   step: build PDF layout for \"Energy & energy security\"\n",
      "[23:39:03]   step: PDF saved → reports_v6/energy-and-energy-security/topic_report.pdf\n",
      "[23:39:03] ✔ topic done: \"Energy & energy security\" in 267.8s | PDF → reports_v6/energy-and-energy-security/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  27%|███████████▏                              | 8/30 [40:15<1:37:16, 265.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:03] ▶ topic: \"Enlargement & neighbourhood policy\" → reports_v6/enlargement-and-neighbourhood-policy\n",
      "[23:39:03]   step: filter count → 2844 speeches in df for this topic (before guardrails)\n",
      "[23:39:03]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6032364d6b43e483cd89afa6b48b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:53]     done in 50.4s | rows=11 | pw=none\n",
      "[23:39:53]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[23:39:53]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05149d34e2b4e0e880482d4cea4dd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:46]     done in 53.0s | rows=11 | pw=ok\n",
      "[23:40:46]     bins_ok=5 latest_ok=2023-01-01 00:00:00 CPC_max=0.029007621302950263\n",
      "[23:40:46]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd23c0ff4a04c5cb433ed9e5bbf25ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:41:40]     done in 53.8s | rows=11 | pw=ok\n",
      "[23:41:40]     bins_ok=5 latest_ok=2023-01-01 00:00:00 CPC_max=0.04204899925647839\n",
      "[23:41:40]   step: save CSVs\n",
      "[23:41:40]     CSVs saved.\n",
      "[23:41:40]   step: build PDF layout for \"Enlargement & neighbourhood policy\"\n",
      "[23:41:40]   step: PDF saved → reports_v6/enlargement-and-neighbourhood-policy/topic_report.pdf\n",
      "[23:41:40] ✔ topic done: \"Enlargement & neighbourhood policy\" in 157.6s | PDF → reports_v6/enlargement-and-neighbourhood-policy/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  30%|████████████▌                             | 9/30 [42:53<1:21:03, 231.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:41:40] ▶ topic: \"Foreign policy — Americas\" → reports_v6/foreign-policy-americas\n",
      "[23:41:40]   step: filter count → 2655 speeches in df for this topic (before guardrails)\n",
      "[23:41:40]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61d3881457c4ea28b69d99a82f87c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:42:31]     done in 51.3s | rows=11 | pw=ok\n",
      "[23:42:31]     bins_ok=1 latest_ok=2021-01-01 00:00:00 CPC_max=0.06092986764646691\n",
      "[23:42:31]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ce1646e50e44438f93c526861cb065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:26]     done in 54.3s | rows=11 | pw=ok\n",
      "[23:43:26]     bins_ok=7 latest_ok=2025-01-01 00:00:00 CPC_max=0.040164930512165374\n",
      "[23:43:26]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602be0f51b40412fbfad4b3810ce262c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:19]     done in 53.2s | rows=11 | pw=ok\n",
      "[23:44:19]     bins_ok=7 latest_ok=2025-01-01 00:00:00 CPC_max=0.061193472746280765\n",
      "[23:44:19]   step: save CSVs\n",
      "[23:44:19]     CSVs saved.\n",
      "[23:44:19]   step: build PDF layout for \"Foreign policy — Americas\"\n",
      "[23:44:19]   step: PDF saved → reports_v6/foreign-policy-americas/topic_report.pdf\n",
      "[23:44:19] ✔ topic done: \"Foreign policy — Americas\" in 159.2s | PDF → reports_v6/foreign-policy-americas/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  33%|█████████████▋                           | 10/30 [45:32<1:09:45, 209.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:19] ▶ topic: \"Foreign policy — Asia-Pacific\" → reports_v6/foreign-policy-asia-pacific\n",
      "[23:44:19]   step: filter count → 956 speeches in df for this topic (before guardrails)\n",
      "[23:44:19]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00b6fa2b54746cd8a0308d7f7c46c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:44]     done in 24.3s | rows=10 | pw=none\n",
      "[23:44:44]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[23:44:44]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5847022e37a40ed9a92c8b0390b724d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:04]     done in 20.1s | rows=10 | pw=ok\n",
      "[23:45:04]     bins_ok=1 latest_ok=2022-01-01 00:00:00 CPC_max=0.030443242275798296\n",
      "[23:45:04]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a55c227a52453a87a076b5b754a5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:23]     done in 19.5s | rows=10 | pw=ok\n",
      "[23:45:23]     bins_ok=1 latest_ok=2022-01-01 00:00:00 CPC_max=0.0332040882552528\n",
      "[23:45:23]   step: save CSVs\n",
      "[23:45:23]     CSVs saved.\n",
      "[23:45:23]   step: build PDF layout for \"Foreign policy — Asia-Pacific\"\n",
      "[23:45:24]   step: PDF saved → reports_v6/foreign-policy-asia-pacific/topic_report.pdf\n",
      "[23:45:24] ✔ topic done: \"Foreign policy — Asia-Pacific\" in 64.3s | PDF → reports_v6/foreign-policy-asia-pacific/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  37%|███████████████▊                           | 11/30 [46:36<52:13, 164.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:24] ▶ topic: \"Foreign policy — Europe & Eastern Neighbourhood\" → reports_v6/foreign-policy-europe-and-eastern-neighbourhood\n",
      "[23:45:24]   step: filter count → 6807 speeches in df for this topic (before guardrails)\n",
      "[23:45:24]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47b7f73a57a460ca64396431a5be6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:47:20]     done in 116.2s | rows=11 | pw=ok\n",
      "[23:47:20]     bins_ok=3 latest_ok=2023-01-01 00:00:00 CPC_max=0.046839587564849544\n",
      "[23:47:20]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20954a9c2754b2aa743e5e3d5b8180b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:35]     done in 135.4s | rows=11 | pw=ok\n",
      "[23:49:35]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.024967707789997212\n",
      "[23:49:35]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a532572d094ad69b6a888cf74724c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:54]     done in 138.4s | rows=11 | pw=ok\n",
      "[23:51:54]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.12567029581601577\n",
      "[23:51:54]   step: save CSVs\n",
      "[23:51:54]     CSVs saved.\n",
      "[23:51:54]   step: build PDF layout for \"Foreign policy — Europe & Eastern Neighbourhood\"\n",
      "[23:51:55]   step: PDF saved → reports_v6/foreign-policy-europe-and-eastern-neighbourhood/topic_report.pdf\n",
      "[23:51:55] ✔ topic done: \"Foreign policy — Europe & Eastern Neighbourhood\" in 390.8s | PDF → reports_v6/foreign-policy-europe-and-eastern-neighbourhood/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  40%|████████████████▍                        | 12/30 [53:07<1:10:05, 233.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:51:55] ▶ topic: \"Foreign policy — Middle East & North Africa\" → reports_v6/foreign-policy-middle-east-and-north-africa\n",
      "[23:51:55]   step: filter count → 4195 speeches in df for this topic (before guardrails)\n",
      "[23:51:55]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b7e5c9d52342cfaab8b83b22bb359c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:15]     done in 80.6s | rows=11 | pw=none\n",
      "[23:53:15]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[23:53:15]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bd0062e764472285f63384d19a2074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:54:47]     done in 91.7s | rows=11 | pw=ok\n",
      "[23:54:47]     bins_ok=9 latest_ok=2024-01-01 00:00:00 CPC_max=0.06760599637545363\n",
      "[23:54:47]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcd13ff9100430d96441ebc04c71249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:19]     done in 92.1s | rows=11 | pw=ok\n",
      "[23:56:19]     bins_ok=9 latest_ok=2024-01-01 00:00:00 CPC_max=0.07041668827710333\n",
      "[23:56:19]   step: save CSVs\n",
      "[23:56:19]     CSVs saved.\n",
      "[23:56:19]   step: build PDF layout for \"Foreign policy — Middle East & North Africa\"\n",
      "[23:56:20]   step: PDF saved → reports_v6/foreign-policy-middle-east-and-north-africa/topic_report.pdf\n",
      "[23:56:20] ✔ topic done: \"Foreign policy — Middle East & North Africa\" in 265.0s | PDF → reports_v6/foreign-policy-middle-east-and-north-africa/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  43%|█████████████████▊                       | 13/30 [57:32<1:08:53, 243.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:20] ▶ topic: \"Foreign policy — Sub-Saharan Africa\" → reports_v6/foreign-policy-sub-saharan-africa\n",
      "[23:56:20]   step: filter count → 1027 speeches in df for this topic (before guardrails)\n",
      "[23:56:20]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a829cc14934598a39879cf8dbda3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:43]     done in 23.7s | rows=10 | pw=none\n",
      "[23:56:43]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[23:56:43]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f00f1f119934ca38da4691ba9fa8a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:02]     done in 19.1s | rows=10 | pw=none\n",
      "[23:57:02]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[23:57:02]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07229fb19bcd420e88133478aa45d9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:21]     done in 18.4s | rows=10 | pw=none\n",
      "[23:57:21]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[23:57:21]   step: save CSVs\n",
      "[23:57:21]     CSVs saved.\n",
      "[23:57:21]   step: build PDF layout for \"Foreign policy — Sub-Saharan Africa\"\n",
      "[23:57:21]   step: PDF saved → reports_v6/foreign-policy-sub-saharan-africa/topic_report.pdf\n",
      "[23:57:21] ✔ topic done: \"Foreign policy — Sub-Saharan Africa\" in 61.5s | PDF → reports_v6/foreign-policy-sub-saharan-africa/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  47%|████████████████████                       | 14/30 [58:34<50:12, 188.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:57:21] ▶ topic: \"Health\" → reports_v6/health\n",
      "[23:57:21]   step: filter count → 4529 speeches in df for this topic (before guardrails)\n",
      "[23:57:21]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce26840566c449d91c5bb05ba93643f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:45]     done in 83.6s | rows=11 | pw=ok\n",
      "[23:58:45]     bins_ok=3 latest_ok=2023-01-01 00:00:00 CPC_max=0.059408918488772985\n",
      "[23:58:45]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8571dbcfaebc4407b5913ba12f376ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:21]     done in 96.1s | rows=11 | pw=ok\n",
      "[00:00:21]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.04236106398103326\n",
      "[00:00:21]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a1149973634f43a070e19d0787be78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:57]     done in 96.7s | rows=11 | pw=ok\n",
      "[00:01:57]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.04382748506354786\n",
      "[00:01:57]   step: save CSVs\n",
      "[00:01:57]     CSVs saved.\n",
      "[00:01:57]   step: build PDF layout for \"Health\"\n",
      "[00:01:58]   step: PDF saved → reports_v6/health/topic_report.pdf\n",
      "[00:01:58] ✔ topic done: \"Health\" in 276.9s | PDF → reports_v6/health/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  50%|████████████████████▌                    | 15/30 [1:03:11<53:44, 215.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:01:58] ▶ topic: \"Institutional affairs & governance\" → reports_v6/institutional-affairs-and-governance\n",
      "[00:01:58]   step: filter count → 5378 speeches in df for this topic (before guardrails)\n",
      "[00:01:58]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e491589a5bf04735b9e0a8cb13da38ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:03:31]     done in 92.8s | rows=11 | pw=ok\n",
      "[00:03:31]     bins_ok=3 latest_ok=2023-01-01 00:00:00 CPC_max=0.041146661006434666\n",
      "[00:03:31]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb82b5df2c84ec293bdf0e8dda77c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:05:21]     done in 110.2s | rows=11 | pw=ok\n",
      "[00:05:21]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.03712445940004549\n",
      "[00:05:21]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48323ece87cb45a7809aec84a925e064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:14]     done in 113.4s | rows=11 | pw=ok\n",
      "[00:07:14]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.050152685809933414\n",
      "[00:07:14]   step: save CSVs\n",
      "[00:07:14]     CSVs saved.\n",
      "[00:07:14]   step: build PDF layout for \"Institutional affairs & governance\"\n",
      "[00:07:15]   step: PDF saved → reports_v6/institutional-affairs-and-governance/topic_report.pdf\n",
      "[00:07:15] ✔ topic done: \"Institutional affairs & governance\" in 317.0s | PDF → reports_v6/institutional-affairs-and-governance/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  53%|█████████████████████▊                   | 16/30 [1:08:28<57:19, 245.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:15] ▶ topic: \"Justice, security & policing\" → reports_v6/justice-security-and-policing\n",
      "[00:07:15]   step: filter count → 3314 speeches in df for this topic (before guardrails)\n",
      "[00:07:15]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20883e92faea4f44b4a9431e2cd9c0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:08:13]     done in 57.6s | rows=11 | pw=none\n",
      "[00:08:13]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:08:13]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852b6747edbd42649c42e084fc0cf34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:09:17]     done in 63.9s | rows=11 | pw=ok\n",
      "[00:09:17]     bins_ok=6 latest_ok=2025-01-01 00:00:00 CPC_max=0.030035118315010913\n",
      "[00:09:17]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9a88f4952e44e5b6bd0f6a6d78b0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:21]     done in 64.5s | rows=11 | pw=ok\n",
      "[00:10:21]     bins_ok=6 latest_ok=2025-01-01 00:00:00 CPC_max=0.04113036926376177\n",
      "[00:10:21]   step: save CSVs\n",
      "[00:10:21]     CSVs saved.\n",
      "[00:10:21]   step: build PDF layout for \"Justice, security & policing\"\n",
      "[00:10:22]   step: PDF saved → reports_v6/justice-security-and-policing/topic_report.pdf\n",
      "[00:10:22] ✔ topic done: \"Justice, security & policing\" in 186.5s | PDF → reports_v6/justice-security-and-policing/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  57%|███████████████████████▏                 | 17/30 [1:11:34<49:22, 227.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:10:22] ▶ topic: \"Media, information & disinformation\" → reports_v6/media-information-and-disinformation\n",
      "[00:10:22]   step: filter count → 2012 speeches in df for this topic (before guardrails)\n",
      "[00:10:22]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07abecba889946d6813bc867a91956ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:03]     done in 41.4s | rows=10 | pw=none\n",
      "[00:11:03]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:11:03]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f6ca66131e400a9a7fe80db7d40144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:48]     done in 45.3s | rows=10 | pw=ok\n",
      "[00:11:48]     bins_ok=5 latest_ok=2024-01-01 00:00:00 CPC_max=0.027449693931147018\n",
      "[00:11:48]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd1e99cc30d471da52773ec58ec201b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:33]     done in 45.0s | rows=10 | pw=ok\n",
      "[00:12:33]     bins_ok=5 latest_ok=2024-01-01 00:00:00 CPC_max=0.03475289473624651\n",
      "[00:12:33]   step: save CSVs\n",
      "[00:12:33]     CSVs saved.\n",
      "[00:12:33]   step: build PDF layout for \"Media, information & disinformation\"\n",
      "[00:12:34]   step: PDF saved → reports_v6/media-information-and-disinformation/topic_report.pdf\n",
      "[00:12:34] ✔ topic done: \"Media, information & disinformation\" in 132.1s | PDF → reports_v6/media-information-and-disinformation/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  60%|████████████████████████▌                | 18/30 [1:13:46<39:49, 199.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:34] ▶ topic: \"Migration & asylum\" → reports_v6/migration-and-asylum\n",
      "[00:12:34]   step: filter count → 6863 speeches in df for this topic (before guardrails)\n",
      "[00:12:34]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57454da5109f478ba290b42e534a3c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:14:29]     done in 115.7s | rows=10 | pw=ok\n",
      "[00:14:29]     bins_ok=3 latest_ok=2023-01-01 00:00:00 CPC_max=0.052932842726926534\n",
      "[00:14:29]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605586f12a8d4572a17cba395ad5ece5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:16:44]     done in 134.2s | rows=10 | pw=ok\n",
      "[00:16:44]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.03297528472895107\n",
      "[00:16:44]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba35e211e7ec41d080e499615677648d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:18:58]     done in 134.9s | rows=10 | pw=ok\n",
      "[00:18:58]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.0358150184283815\n",
      "[00:18:58]   step: save CSVs\n",
      "[00:18:58]     CSVs saved.\n",
      "[00:18:58]   step: build PDF layout for \"Migration & asylum\"\n",
      "[00:19:00]   step: PDF saved → reports_v6/migration-and-asylum/topic_report.pdf\n",
      "[00:19:00] ✔ topic done: \"Migration & asylum\" in 386.0s | PDF → reports_v6/migration-and-asylum/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  63%|█████████████████████████▉               | 19/30 [1:20:12<46:47, 255.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:19:00] ▶ topic: \"Monetary & financial stability\" → reports_v6/monetary-and-financial-stability\n",
      "[00:19:00]   step: filter count → 2339 speeches in df for this topic (before guardrails)\n",
      "[00:19:00]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e946c01697407d86a76efa68c8d5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:19:41]     done in 41.0s | rows=11 | pw=none\n",
      "[00:19:41]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:19:41]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55dd92b12db48298f0d81b5d1e2e15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:20:24]     done in 43.5s | rows=11 | pw=ok\n",
      "[00:20:24]     bins_ok=4 latest_ok=2018-01-01 00:00:00 CPC_max=0.02518752059689635\n",
      "[00:20:24]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9dc97884934ef5918941b0ced94a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:21:08]     done in 44.1s | rows=11 | pw=ok\n",
      "[00:21:08]     bins_ok=4 latest_ok=2018-01-01 00:00:00 CPC_max=0.042044462903326564\n",
      "[00:21:08]   step: save CSVs\n",
      "[00:21:08]     CSVs saved.\n",
      "[00:21:08]   step: build PDF layout for \"Monetary & financial stability\"\n",
      "[00:21:09]   step: PDF saved → reports_v6/monetary-and-financial-stability/topic_report.pdf\n",
      "[00:21:09] ✔ topic done: \"Monetary & financial stability\" in 129.0s | PDF → reports_v6/monetary-and-financial-stability/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  67%|███████████████████████████▎             | 20/30 [1:22:21<36:13, 217.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:21:09] ▶ topic: \"Procedural & Parliamentary business\" → reports_v6/procedural-and-parliamentary-business\n",
      "[00:21:09]   step: filter count → 23685 speeches in df for this topic (before guardrails)\n",
      "[00:21:09]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ccaa59cedc405aa6834b6aec2790e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:26:45]     done in 336.1s | rows=11 | pw=ok\n",
      "[00:26:45]     bins_ok=10 latest_ok=2025-01-01 00:00:00 CPC_max=0.032377938030626975\n",
      "[00:26:45]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4002bc2d8a74132902b89777738f8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:32:34]     done in 348.7s | rows=11 | pw=ok\n",
      "[00:32:34]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.014436044856369727\n",
      "[00:32:34]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9789707fc0cd43d09908381e37e9dcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:38:25]     done in 351.3s | rows=11 | pw=ok\n",
      "[00:38:25]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.02625492788259982\n",
      "[00:38:25]   step: save CSVs\n",
      "[00:38:25]     CSVs saved.\n",
      "[00:38:25]   step: build PDF layout for \"Procedural & Parliamentary business\"\n",
      "[00:38:26]   step: PDF saved → reports_v6/procedural-and-parliamentary-business/topic_report.pdf\n",
      "[00:38:26] ✔ topic done: \"Procedural & Parliamentary business\" in 1036.8s | PDF → reports_v6/procedural-and-parliamentary-business/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  70%|███████████████████████████▎           | 21/30 [1:39:38<1:09:30, 463.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:38:26] ▶ topic: \"Research, innovation & space\" → reports_v6/research-innovation-and-space\n",
      "[00:38:26]   step: filter count → 1098 speeches in df for this topic (before guardrails)\n",
      "[00:38:26]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a175a87dfa45309a6a7990b0799b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:38:52]     done in 26.8s | rows=10 | pw=none\n",
      "[00:38:52]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:38:52]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c477279aea45fea9f61b6d2d090557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:39:14]     done in 21.3s | rows=10 | pw=ok\n",
      "[00:39:14]     bins_ok=1 latest_ok=2024-01-01 00:00:00 CPC_max=0.02135981669253606\n",
      "[00:39:14]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5f1ace113c4b3ba22eab5a9771838a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:39:34]     done in 20.4s | rows=10 | pw=ok\n",
      "[00:39:34]     bins_ok=1 latest_ok=2024-01-01 00:00:00 CPC_max=0.024143781123930234\n",
      "[00:39:34]   step: save CSVs\n",
      "[00:39:34]     CSVs saved.\n",
      "[00:39:34]   step: build PDF layout for \"Research, innovation & space\"\n",
      "[00:39:34]   step: PDF saved → reports_v6/research-innovation-and-space/topic_report.pdf\n",
      "[00:39:34] ✔ topic done: \"Research, innovation & space\" in 69.0s | PDF → reports_v6/research-innovation-and-space/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  73%|██████████████████████████████           | 22/30 [1:40:47<45:59, 344.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:39:34] ▶ topic: \"Rule of law & fundamental rights\" → reports_v6/rule-of-law-and-fundamental-rights\n",
      "[00:39:34]   step: filter count → 17208 speeches in df for this topic (before guardrails)\n",
      "[00:39:34]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b69bb00017485f936addcc408a8a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:44:11]     done in 276.9s | rows=11 | pw=ok\n",
      "[00:44:11]     bins_ok=8 latest_ok=2023-01-01 00:00:00 CPC_max=0.0314824227908932\n",
      "[00:44:11]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a19bd33e2de4d5b92b8a5bcf1240e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:49:05]     done in 293.9s | rows=11 | pw=ok\n",
      "[00:49:05]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.03625478308685593\n",
      "[00:49:05]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515a7b3ef84f46c08a93b179f70486bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:54:03]     done in 297.5s | rows=11 | pw=ok\n",
      "[00:54:03]     bins_ok=11 latest_ok=2025-01-01 00:00:00 CPC_max=0.038898469582491955\n",
      "[00:54:03]   step: save CSVs\n",
      "[00:54:03]     CSVs saved.\n",
      "[00:54:03]   step: build PDF layout for \"Rule of law & fundamental rights\"\n",
      "[00:54:04]   step: PDF saved → reports_v6/rule-of-law-and-fundamental-rights/topic_report.pdf\n",
      "[00:54:04] ✔ topic done: \"Rule of law & fundamental rights\" in 869.4s | PDF → reports_v6/rule-of-law-and-fundamental-rights/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  77%|███████████████████████████████▍         | 23/30 [1:55:17<58:36, 502.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:54:04] ▶ topic: \"Security & defence\" → reports_v6/security-and-defence\n",
      "[00:54:04]   step: filter count → 4084 speeches in df for this topic (before guardrails)\n",
      "[00:54:04]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becc12d485294b80ae0ff622ea6bc0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:55:19]     done in 75.2s | rows=11 | pw=ok\n",
      "[00:55:19]     bins_ok=1 latest_ok=2023-01-01 00:00:00 CPC_max=0.052268053454380084\n",
      "[00:55:19]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdf6b69f2df4d3d9ebc79a914165a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:56:45]     done in 86.1s | rows=11 | pw=ok\n",
      "[00:56:45]     bins_ok=9 latest_ok=2025-01-01 00:00:00 CPC_max=0.03346005418730572\n",
      "[00:56:45]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f029b0acaf4384a1178083a43a637d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:11]     done in 85.7s | rows=11 | pw=ok\n",
      "[00:58:11]     bins_ok=9 latest_ok=2025-01-01 00:00:00 CPC_max=0.06475367889776883\n",
      "[00:58:11]   step: save CSVs\n",
      "[00:58:11]     CSVs saved.\n",
      "[00:58:11]   step: build PDF layout for \"Security & defence\"\n",
      "[00:58:11]   step: PDF saved → reports_v6/security-and-defence/topic_report.pdf\n",
      "[00:58:11] ✔ topic done: \"Security & defence\" in 247.5s | PDF → reports_v6/security-and-defence/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  80%|████████████████████████████████▊        | 24/30 [1:59:24<42:35, 425.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:11] ▶ topic: \"Security & policing\" → reports_v6/security-and-policing\n",
      "[00:58:11]   step: filter count → 41 speeches in df for this topic (before guardrails)\n",
      "[00:58:11]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc5da99f17c462b991e06179bd69733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:23]     done in 11.9s | rows=1 | pw=none\n",
      "[00:58:23]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:58:23]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb37cb820f44ac3bb6f1eb348148d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:31]     done in 7.7s | rows=1 | pw=none\n",
      "[00:58:31]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:58:31]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f34d44f51904e06a425dd1167cf1a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:38]     done in 6.7s | rows=1 | pw=none\n",
      "[00:58:38]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:58:38]   step: save CSVs\n",
      "[00:58:38]     CSVs saved.\n",
      "[00:58:38]   step: build PDF layout for \"Security & policing\"\n",
      "[00:58:38]   step: PDF saved → reports_v6/security-and-policing/topic_report.pdf\n",
      "[00:58:38] ✔ topic done: \"Security & policing\" in 26.8s | PDF → reports_v6/security-and-policing/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  83%|██████████████████████████████████▏      | 25/30 [1:59:51<25:30, 306.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:38] ▶ topic: \"Single market, competition & consumer protection\" → reports_v6/single-market-competition-and-consumer-protection\n",
      "[00:58:38]   step: filter count → 3302 speeches in df for this topic (before guardrails)\n",
      "[00:58:38]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff18543fe27411bb5d06c346115d509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:59:34]     done in 55.9s | rows=11 | pw=none\n",
      "[00:59:34]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[00:59:34]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e9510fb334434f8bbc217e61d79b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:00:45]     done in 70.7s | rows=11 | pw=ok\n",
      "[01:00:45]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.040029495684586844\n",
      "[01:00:45]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4d317c23f24751a6b8e866a1de66e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:02:00]     done in 74.7s | rows=11 | pw=ok\n",
      "[01:02:00]     bins_ok=9 latest_ok=2023-01-01 00:00:00 CPC_max=0.048004157544610994\n",
      "[01:02:00]   step: save CSVs\n",
      "[01:02:00]     CSVs saved.\n",
      "[01:02:00]   step: build PDF layout for \"Single market, competition & consumer protection\"\n",
      "[01:02:00]   step: PDF saved → reports_v6/single-market-competition-and-consumer-protection/topic_report.pdf\n",
      "[01:02:00] ✔ topic done: \"Single market, competition & consumer protection\" in 201.9s | PDF → reports_v6/single-market-competition-and-consumer-protection/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  87%|███████████████████████████████████▌     | 26/30 [2:03:13<18:19, 274.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:02:00] ▶ topic: \"Social policy & employment\" → reports_v6/social-policy-and-employment\n",
      "[01:02:00]   step: filter count → 7525 speeches in df for this topic (before guardrails)\n",
      "[01:02:00]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851e1d46c4b745c7925cf64d5053d435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:04:05]     done in 124.3s | rows=10 | pw=ok\n",
      "[01:04:05]     bins_ok=3 latest_ok=2023-01-01 00:00:00 CPC_max=0.04568527396685119\n",
      "[01:04:05]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7652a5d78a4448ca36b90d0e4fce874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:06:36]     done in 151.6s | rows=10 | pw=ok\n",
      "[01:06:36]     bins_ok=10 latest_ok=2024-01-01 00:00:00 CPC_max=0.041476691412939484\n",
      "[01:06:36]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dac9f1960b6481fbd8427b5bd50a25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:08]     done in 152.4s | rows=10 | pw=ok\n",
      "[01:09:08]     bins_ok=10 latest_ok=2024-01-01 00:00:00 CPC_max=0.04723697924084339\n",
      "[01:09:08]   step: save CSVs\n",
      "[01:09:09]     CSVs saved.\n",
      "[01:09:09]   step: build PDF layout for \"Social policy & employment\"\n",
      "[01:09:09]   step: PDF saved → reports_v6/social-policy-and-employment/topic_report.pdf\n",
      "[01:09:09] ✔ topic done: \"Social policy & employment\" in 428.8s | PDF → reports_v6/social-policy-and-employment/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  90%|████████████████████████████████████▉    | 27/30 [2:10:22<16:03, 321.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:09] ▶ topic: \"Taxation & anti-money laundering\" → reports_v6/taxation-and-anti-money-laundering\n",
      "[01:09:09]   step: filter count → 0 speeches in df for this topic (before guardrails)\n",
      "[01:09:09]   step: run mode=speaker (MEP-averaged)\n",
      "[01:09:09]     done in 0.0s | rows=0 | pw=none\n",
      "[01:09:09]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[01:09:09]   step: run mode=speech_capped (per-MEP cap)\n",
      "[01:09:09]     done in 0.0s | rows=0 | pw=none\n",
      "[01:09:09]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[01:09:09]   step: run mode=speech_weighted (as heard)\n",
      "[01:09:09]     done in 0.0s | rows=0 | pw=none\n",
      "[01:09:09]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[01:09:09]   step: save CSVs\n",
      "[01:09:09]     CSVs saved.\n",
      "[01:09:09]   step: build PDF layout for \"Taxation & anti-money laundering\"\n",
      "[01:09:09]   step: PDF saved → reports_v6/taxation-and-anti-money-laundering/topic_report.pdf\n",
      "[01:09:09] ✔ topic done: \"Taxation & anti-money laundering\" in 0.3s | PDF → reports_v6/taxation-and-anti-money-laundering/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  93%|██████████████████████████████████████▎  | 28/30 [2:10:22<07:29, 224.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:09] ▶ topic: \"Trade & globalization\" → reports_v6/trade-and-globalization\n",
      "[01:09:09]   step: filter count → 5979 speeches in df for this topic (before guardrails)\n",
      "[01:09:09]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d35944a797146d8b0b38b576474a813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:43]     done in 93.4s | rows=11 | pw=none\n",
      "[01:10:43]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[01:10:43]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e10b348f5b943bc86942eda74788566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:12:40]     done in 117.4s | rows=11 | pw=ok\n",
      "[01:12:40]     bins_ok=10 latest_ok=2025-01-01 00:00:00 CPC_max=0.036857308243540304\n",
      "[01:12:40]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afce9db56f648668a481b5ef879679b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:14:38]     done in 118.0s | rows=11 | pw=ok\n",
      "[01:14:38]     bins_ok=10 latest_ok=2025-01-01 00:00:00 CPC_max=0.04280351490659047\n",
      "[01:14:38]   step: save CSVs\n",
      "[01:14:38]     CSVs saved.\n",
      "[01:14:38]   step: build PDF layout for \"Trade & globalization\"\n",
      "[01:14:39]   step: PDF saved → reports_v6/trade-and-globalization/topic_report.pdf\n",
      "[01:14:39] ✔ topic done: \"Trade & globalization\" in 329.3s | PDF → reports_v6/trade-and-globalization/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:  97%|███████████████████████████████████████▋ | 29/30 [2:15:51<04:16, 256.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:14:39] ▶ topic: \"Transport & mobility\" → reports_v6/transport-and-mobility\n",
      "[01:14:39]   step: filter count → 2769 speeches in df for this topic (before guardrails)\n",
      "[01:14:39]   step: run mode=speaker (MEP-averaged)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bce8d2bc4b4419a294a6ef364f9faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:15:30]     done in 51.6s | rows=10 | pw=none\n",
      "[01:15:30]     bins_ok=0 latest_ok=None CPC_max=None\n",
      "[01:15:30]   step: run mode=speech_capped (per-MEP cap)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13063f5c3cf4b35a1968bb4dd9bb736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:16:26]     done in 56.0s | rows=10 | pw=ok\n",
      "[01:16:26]     bins_ok=5 latest_ok=2019-01-01 00:00:00 CPC_max=0.020376982914868974\n",
      "[01:16:26]   step: run mode=speech_weighted (as heard)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9227d1e395214f3c896cf4886aa8e085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:17:22]     done in 55.3s | rows=10 | pw=ok\n",
      "[01:17:22]     bins_ok=5 latest_ok=2019-01-01 00:00:00 CPC_max=0.05378946345341698\n",
      "[01:17:22]   step: save CSVs\n",
      "[01:17:22]     CSVs saved.\n",
      "[01:17:22]   step: build PDF layout for \"Transport & mobility\"\n",
      "[01:17:22]   step: PDF saved → reports_v6/transport-and-mobility/topic_report.pdf\n",
      "[01:17:22] ✔ topic done: \"Transport & mobility\" in 163.7s | PDF → reports_v6/transport-and-mobility/topic_report.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics: 100%|█████████████████████████████████████████| 30/30 [2:18:35<00:00, 277.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:17:22] Batch finished → reports_v6/batch_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:17:23] Topics summary saved → reports_v6/topics_summary_v6.csv\n"
     ]
    }
   ],
   "source": [
    "summary_df = run_all_topics(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85207a4",
   "metadata": {},
   "source": [
    "## Redo report summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f5699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:53]   build 9-panel report → reports_v6/_all_speeches/topic_report_extended.pdf\n",
      "[12:25:54]   build 9-panel report → reports_v6/agriculture-and-fisheries/topic_report_extended.pdf\n",
      "[12:25:54]   build 9-panel report → reports_v6/climate-environment-and-biodiversity/topic_report_extended.pdf\n",
      "[12:25:55]   build 9-panel report → reports_v6/development-and-humanitarian-aid/topic_report_extended.pdf\n",
      "[12:25:55]   build 9-panel report → reports_v6/digital-policy-and-data-protection/topic_report_extended.pdf\n",
      "[12:25:56]   build 9-panel report → reports_v6/eu-budget-and-mff/topic_report_extended.pdf\n",
      "[12:25:56]   build 9-panel report → reports_v6/economy-and-industrial-policy/topic_report_extended.pdf\n",
      "[12:25:57]   build 9-panel report → reports_v6/education-culture-and-sport/topic_report_extended.pdf\n",
      "[12:25:57]   build 9-panel report → reports_v6/energy-and-energy-security/topic_report_extended.pdf\n",
      "[12:25:58]   build 9-panel report → reports_v6/enlargement-and-neighbourhood-policy/topic_report_extended.pdf\n",
      "[12:25:58]   build 9-panel report → reports_v6/foreign-policy-americas/topic_report_extended.pdf\n",
      "[12:25:58]   build 9-panel report → reports_v6/foreign-policy-asia-pacific/topic_report_extended.pdf\n",
      "[12:25:59]   build 9-panel report → reports_v6/foreign-policy-europe-and-eastern-neighbourhood/topic_report_extended.pdf\n",
      "[12:25:59]   build 9-panel report → reports_v6/foreign-policy-middle-east-and-north-africa/topic_report_extended.pdf\n",
      "[12:26:00]   build 9-panel report → reports_v6/foreign-policy-sub-saharan-africa/topic_report_extended.pdf\n",
      "[12:26:00]   build 9-panel report → reports_v6/health/topic_report_extended.pdf\n",
      "[12:26:01]   build 9-panel report → reports_v6/institutional-affairs-and-governance/topic_report_extended.pdf\n",
      "[12:26:01]   build 9-panel report → reports_v6/justice-security-and-policing/topic_report_extended.pdf\n",
      "[12:26:01]   build 9-panel report → reports_v6/media-information-and-disinformation/topic_report_extended.pdf\n",
      "[12:26:02]   build 9-panel report → reports_v6/migration-and-asylum/topic_report_extended.pdf\n",
      "[12:26:02]   build 9-panel report → reports_v6/monetary-and-financial-stability/topic_report_extended.pdf\n",
      "[12:26:03]   build 9-panel report → reports_v6/procedural-and-parliamentary-business/topic_report_extended.pdf\n",
      "[12:26:03]   build 9-panel report → reports_v6/research-innovation-and-space/topic_report_extended.pdf\n",
      "[12:26:03]   build 9-panel report → reports_v6/rule-of-law-and-fundamental-rights/topic_report_extended.pdf\n",
      "[12:26:04]   build 9-panel report → reports_v6/security-and-defence/topic_report_extended.pdf\n",
      "[12:26:04]   build 9-panel report → reports_v6/security-and-policing/topic_report_extended.pdf\n",
      "[12:26:04]   build 9-panel report → reports_v6/single-market-competition-and-consumer-protection/topic_report_extended.pdf\n",
      "[12:26:05]   build 9-panel report → reports_v6/social-policy-and-employment/topic_report_extended.pdf\n",
      "[12:26:05]   build 9-panel report → reports_v6/taxation-and-anti-money-laundering/topic_report_extended.pdf\n",
      "[12:26:05]   build 9-panel report → reports_v6/trade-and-globalization/topic_report_extended.pdf\n",
      "[12:26:05]   build 9-panel report → reports_v6/transport-and-mobility/topic_report_extended.pdf\n",
      "[12:26:06] All 9-panel PDFs rebuilt.\n"
     ]
    }
   ],
   "source": [
    "import os, re, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# ---------- logging ----------\n",
    "def _now():\n",
    "    return dt.datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "def log(msg):\n",
    "    print(f\"[{_now()}] {msg}\", flush=True)\n",
    "\n",
    "# ---------- topics & paths ----------\n",
    "RAW_TOPICS = [\n",
    "    \"Agriculture & fisheries\",\n",
    "    \"Climate, environment & biodiversity\",\n",
    "    \"Development & humanitarian aid\",\n",
    "    \"Digital policy & data protection\",\n",
    "    \"EU budget & MFF\",\n",
    "    \"Economy & industrial policy\",\n",
    "    \"Education, culture & sport\",\n",
    "    \"Energy & energy security\",\n",
    "    \"Enlargement & neighbourhood policy\",\n",
    "    \"Foreign policy — Americas\",\n",
    "    \"Foreign policy — Asia-Pacific\",\n",
    "    \"Foreign policy — Asia-Pacific\",\n",
    "    \"Foreign policy — Europe & Eastern Neighbourhood\",\n",
    "    \"Foreign policy — Europe &amp; Eastern Neighbourhood\",\n",
    "    \"Foreign policy — Middle East & North Africa\",\n",
    "    \"Foreign policy — Sub-Saharan Africa\",\n",
    "    \"Foreign policy — Sub-Saharan Africa\",\n",
    "    \"Health\",\n",
    "    \"Institutional affairs & governance\",\n",
    "    \"Justice, security & policing\",\n",
    "    \"Media, information & disinformation\",\n",
    "    \"Migration & asylum\",\n",
    "    \"Monetary & financial stability\",\n",
    "    \"Procedural & Parliamentary business\",\n",
    "    \"Research, innovation & space\",\n",
    "    \"Rule of law & fundamental rights\",\n",
    "    \"Security & defence\",\n",
    "    \"Security & policing\",\n",
    "    \"Single market, competition & consumer protection\",\n",
    "    \"Social policy & employment\",\n",
    "    \"Taxation & anti–money laundering\",\n",
    "    \"Trade & globalization\",\n",
    "    \"Transport & mobility\",\n",
    "]\n",
    "\n",
    "def _normalize_topic(t):\n",
    "    t = t.replace(\"&amp;\", \"&\")\n",
    "    t = t.replace(\"\\u2011\", \"-\")\n",
    "    t = t.replace(\"\\u2013\", \"-\")\n",
    "    t = t.replace(\"\\u2014\", \"—\")\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "TOPICS = sorted(set(_normalize_topic(t) for t in RAW_TOPICS))\n",
    "\n",
    "BASE_DIR = \"reports_v6\"\n",
    "\n",
    "def _slugify(name: str) -> str:\n",
    "    s = name.lower()\n",
    "    s = s.replace(\"&\", \"and\")\n",
    "    s = re.sub(r\"[^\\w\\s-]\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \"-\", s).strip(\"-\")\n",
    "    s = re.sub(r\"-+\", \"-\", s)\n",
    "    return s\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ensure_time_and_numeric(df):\n",
    "    df = df.copy()\n",
    "    if \"time_bin\" in df:\n",
    "        df[\"time_bin\"] = pd.to_datetime(df[\"time_bin\"], errors=\"coerce\")\n",
    "    for col in [\"cpc\", \"cpc_adj\", \"obs_bss_tss\", \"ci_lo\", \"ci_hi\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    if \"ok\" not in df.columns:\n",
    "        df[\"ok\"] = True\n",
    "    return df\n",
    "\n",
    "def _ok_rows(df):\n",
    "    df = _ensure_time_and_numeric(df)\n",
    "    ok = df[df[\"ok\"] == True].copy()\n",
    "    return ok.sort_values(\"time_bin\")\n",
    "\n",
    "def _y_limits_cpc(res_list):\n",
    "    \"\"\"\n",
    "    Y-limits for CPC plots.\n",
    "\n",
    "    - Base range on CPC line (0–1 scale).\n",
    "    - Include CI bounds, but ignore insane outliers so the axis\n",
    "      doesn't explode to -1000% if one bootstrap goes wild.\n",
    "    \"\"\"\n",
    "    cpc_vals = []\n",
    "    ci_vals = []\n",
    "\n",
    "    for df in res_list:\n",
    "        if df is None or len(df) == 0:\n",
    "            continue\n",
    "        ok = _ok_rows(df)\n",
    "\n",
    "        if \"cpc\" in ok.columns:\n",
    "            cpc_vals.extend(\n",
    "                ok[\"cpc\"].replace([np.inf, -np.inf], np.nan).dropna().tolist()\n",
    "            )\n",
    "\n",
    "        # collect CI bounds but only if they look reasonable for a share-of-variance metric\n",
    "        if {\"ci_lo\", \"ci_hi\"} <= set(ok.columns):\n",
    "            ci = pd.concat([ok[\"ci_lo\"], ok[\"ci_hi\"]])\n",
    "            ci = pd.to_numeric(ci, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "            # keep only values roughly in [-5%, 50%] on the 0–1 scale\n",
    "            ci = ci[(ci > -0.05) & (ci < 0.5)]\n",
    "            ci_vals.extend(ci.dropna().tolist())\n",
    "\n",
    "    # Fallback if nothing valid\n",
    "    if not cpc_vals and not ci_vals:\n",
    "        return (0.0, 0.05)\n",
    "\n",
    "    vals = cpc_vals + ci_vals\n",
    "    vmin = min(vals)\n",
    "    vmax = max(vals)\n",
    "\n",
    "    # For CPC we always show the baseline at 0\n",
    "    vmin = min(0.0, vmin)\n",
    "\n",
    "    span = vmax - vmin\n",
    "    if span <= 0:\n",
    "        span = 0.05  # small default span (5 percentage points)\n",
    "\n",
    "    # a bit more generous margin so CI never kisses the frame\n",
    "    margin = 0.15 * span\n",
    "    return (vmin - margin, vmax + margin)\n",
    "\n",
    "\n",
    "def _y_limits_cpc_adj(res_list):\n",
    "    \"\"\"\n",
    "    Y-limits for CPC_adj plots.\n",
    "\n",
    "    - Base range on CPC_adj line.\n",
    "    - Include CI bounds, but clamp to a sensible range so one crazy value\n",
    "      doesn't dominate. CPC_adj can be negative, but we cap it around [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    adj_vals = []\n",
    "    ci_vals = []\n",
    "\n",
    "    for df in res_list:\n",
    "        if df is None or len(df) == 0:\n",
    "            continue\n",
    "        ok = _ok_rows(df)\n",
    "\n",
    "        if \"cpc_adj\" in ok.columns:\n",
    "            adj_vals.extend(\n",
    "                ok[\"cpc_adj\"].replace([np.inf, -np.inf], np.nan).dropna().tolist()\n",
    "            )\n",
    "\n",
    "        if {\"ci_lo\", \"ci_hi\"} <= set(ok.columns):\n",
    "            ci = pd.concat([ok[\"ci_lo\"], ok[\"ci_hi\"]])\n",
    "            ci = pd.to_numeric(ci, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "            # keep CI values in a sensible band for adjusted shares\n",
    "            ci = ci[(ci > -0.6) & (ci < 0.6)]\n",
    "            ci_vals.extend(ci.dropna().tolist())\n",
    "\n",
    "    if not adj_vals and not ci_vals:\n",
    "        return (-0.5, 0.05)\n",
    "\n",
    "    vals = adj_vals + ci_vals\n",
    "    vmin = min(vals)\n",
    "    vmax = max(vals)\n",
    "\n",
    "    # Clamp crazy negatives so a few bins don't dominate everything\n",
    "    vmin = max(vmin, -0.5)\n",
    "    vmin = min(vmin, 0.0)\n",
    "\n",
    "    span = vmax - vmin\n",
    "    if span <= 0:\n",
    "        span = 0.05\n",
    "\n",
    "    margin = 0.15 * span\n",
    "    return (vmin - margin, vmax + margin)\n",
    "\n",
    "\n",
    "\n",
    "def _heat_limits(pw_list):\n",
    "    mx = 0.0\n",
    "    for pw in pw_list:\n",
    "        if pw is None or len(pw) == 0 or \"std_dist\" not in (pw.columns if hasattr(pw, \"columns\") else []):\n",
    "            continue\n",
    "        vals = pd.to_numeric(pw[\"std_dist\"], errors=\"coerce\").dropna()\n",
    "        if not vals.empty:\n",
    "            mx = max(mx, float(vals.max()))\n",
    "    if mx <= 0:\n",
    "        mx = 0.01\n",
    "    return (0.0, mx)\n",
    "\n",
    "# ---------- plotting primitives ----------\n",
    "def _fill_ci_band(ax, ok, ci_mask, label=None, alpha=0.18):\n",
    "    if \"ci_lo\" not in ok.columns or \"ci_hi\" not in ok.columns:\n",
    "        return\n",
    "    ci_lo = ok[\"ci_lo\"]\n",
    "    ci_hi = ok[\"ci_hi\"]\n",
    "    mask = ci_mask & ci_lo.notna() & ci_hi.notna()\n",
    "    if not mask.any():\n",
    "        return\n",
    "    x_ord = mdates.date2num(ok.loc[mask, \"time_bin\"])\n",
    "    ax.fill_between(x_ord,\n",
    "                    ci_lo.loc[mask].values,\n",
    "                    ci_hi.loc[mask].values,\n",
    "                    alpha=alpha,\n",
    "                    label=label)\n",
    "\n",
    "def plot_cpc(ax, res_df, title, ylim, show_legend=False):\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    if res_df is None or len(res_df) == 0:\n",
    "        ax.axis(\"off\"); ax.text(0.5, 0.5, \"No data.\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    ok = _ok_rows(res_df)\n",
    "    if ok.empty or \"cpc\" not in ok.columns:\n",
    "        ax.axis(\"off\"); ax.text(0.5, 0.5, \"No valid CPC.\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    # CI band: use any row with ci_lo/hi (this is the engine metric, usually CPC)\n",
    "    ci_mask = ok[\"ci_lo\"].notna() & ok[\"ci_hi\"].notna()\n",
    "    _fill_ci_band(ax, ok, ci_mask, label=\"95% CI (engine metric)\")\n",
    "\n",
    "    # CPC line\n",
    "    ax.plot(ok[\"time_bin\"], ok[\"cpc\"], marker=\"o\", lw=1.8, label=\"CPC (raw)\")\n",
    "\n",
    "    ax.set_ylabel(\"CPC\")\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.axhline(0.0, lw=0.8, alpha=0.7)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(base=2))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "    if show_legend:\n",
    "        ax.legend(loc=\"upper left\", fontsize=8, frameon=False)\n",
    "\n",
    "def plot_cpc_adj(ax, res_df, title, ylim, show_legend=False, note_if_missing=False):\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    if res_df is None or len(res_df) == 0:\n",
    "        ax.axis(\"off\"); ax.text(0.5, 0.5, \"No data.\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    ok = _ok_rows(res_df)\n",
    "    if \"cpc_adj\" not in ok.columns or not ok[\"cpc_adj\"].notna().any():\n",
    "        ax.axis(\"off\")\n",
    "        msg = \"CPC_adj not defined\\n(token-weighted)\" if note_if_missing else \"No CPC_adj values.\"\n",
    "        ax.text(0.5, 0.5, msg, ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    # CI band: only where obs_bss_tss equals cpc_adj (those bins used CPC_adj as engine metric)\n",
    "    if {\"obs_bss_tss\", \"ci_lo\", \"ci_hi\"} <= set(ok.columns):\n",
    "        ci_mask = ok[\"cpc_adj\"].notna() & np.isclose(ok[\"obs_bss_tss\"], ok[\"cpc_adj\"], atol=1e-10)\n",
    "        _fill_ci_band(ax, ok, ci_mask, label=\"95% CI (engine metric)\")\n",
    "\n",
    "    # CPC_adj line\n",
    "    ax.plot(ok[\"time_bin\"], ok[\"cpc_adj\"], marker=\"s\", lw=1.6, linestyle=\"--\", label=\"CPC_adj\")\n",
    "\n",
    "    ax.set_ylabel(\"CPC_adj\")\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.axhline(0.0, lw=0.8, alpha=0.7)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator(base=2))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "    if show_legend:\n",
    "        ax.legend(loc=\"upper left\", fontsize=8, frameon=False)\n",
    "\n",
    "def plot_heatmap(ax, pw_df, title, vmin, vmax):\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    if pw_df is None or len(pw_df) == 0 or {\"party_a\",\"party_b\",\"std_dist\"} - set(pw_df.columns):\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0.5, 0.5, \"No pairwise table.\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    d = pw_df.copy()\n",
    "    d[\"std_dist\"] = pd.to_numeric(d[\"std_dist\"], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[\"std_dist\"])\n",
    "    if d.empty:\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0.5, 0.5, \"No numeric distances.\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "        return\n",
    "\n",
    "    parties = sorted(set(d[\"party_a\"]).union(set(d[\"party_b\"])))\n",
    "    idx = {p: i for i, p in enumerate(parties)}\n",
    "    M = np.zeros((len(parties), len(parties)), dtype=float)\n",
    "    for _, r in d.iterrows():\n",
    "        i, j = idx[r[\"party_a\"]], idx[r[\"party_b\"]]\n",
    "        M[i, j] = r[\"std_dist\"]\n",
    "        M[j, i] = r[\"std_dist\"]\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "\n",
    "    # keep same info, just cleaner\n",
    "    im = ax.imshow(M, aspect=\"auto\", vmin=vmin, vmax=vmax)\n",
    "\n",
    "    ax.set_xticks(range(len(parties)))\n",
    "    ax.set_yticks(range(len(parties)))\n",
    "    ax.set_xticklabels(parties, rotation=45, ha=\"right\", fontsize=7)\n",
    "    ax.set_yticklabels(parties, fontsize=7)\n",
    "    ax.tick_params(axis=\"x\", pad=2)\n",
    "\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.04, pad=0.03)\n",
    "    cbar.set_label(\"std. centroid distance\", fontsize=7)\n",
    "    cbar.ax.tick_params(labelsize=7)\n",
    "\n",
    "\n",
    "# ---------- full 9-panel report ----------\n",
    "def build_topic_report_9panels(topic_title,\n",
    "                               res_meps, res_cap, res_w,\n",
    "                               pw_meps, pw_cap, pw_w,\n",
    "                               outpath):\n",
    "    log(f\"  build 9-panel report → {outpath}\")\n",
    "\n",
    "    ylim_cpc     = _y_limits_cpc([res_meps, res_cap, res_w])\n",
    "    ylim_cpc_adj = _y_limits_cpc_adj([res_meps, res_cap, res_w])\n",
    "    vmin, vmax   = _heat_limits([pw_meps, pw_cap, pw_w])\n",
    "\n",
    "    if os.path.exists(outpath):\n",
    "        os.remove(outpath)\n",
    "\n",
    "    # base font\n",
    "    plt.rcParams.update({\"font.size\": 10})\n",
    "\n",
    "    # *** BIGGER, TALLER PAGE ***\n",
    "    # still wide like A4 landscape, but extra vertical space so rows are nice and high\n",
    "    fig = plt.figure(figsize=(11.69, 12.0))\n",
    "\n",
    "    # Layout: 5 rows x 3 cols\n",
    "    # row0: title (1x3)\n",
    "    # row1: CPC (3)\n",
    "    # row2: CPC_adj (3)\n",
    "    # row3: heatmaps (3)\n",
    "    # row4: text block (1x3)\n",
    "    gs = GridSpec(\n",
    "        5, 3, figure=fig,\n",
    "        # More weight for the 3 data rows, slimmer title/footer.\n",
    "        height_ratios=[1.1, 4.3, 4.3, 4.3, 1.6],\n",
    "        # Smaller hspace so the graphs themselves get more height.\n",
    "        hspace=0.35,\n",
    "        wspace=0.38\n",
    "    )\n",
    "\n",
    "    # ---- Title row ----\n",
    "    ax_title = fig.add_subplot(gs[0, :])\n",
    "    ax_title.axis(\"off\")\n",
    "\n",
    "    title_str = f\"European Parliament Rhetorical Polarization — {topic_title}\"\n",
    "    subtitle_str = (\n",
    "        \"Row 1: CPC (raw share of variance in rhetoric explained by party) with 95% bootstrap bands \"\n",
    "        \"for the engine metric.\\n\"\n",
    "        \"Row 2: adjusted CPC (CPC_adj). Row 3: standardized pairwise distances between party centroids \"\n",
    "        \"in the latest valid year.\"\n",
    "    )\n",
    "\n",
    "    ax_title.text(\n",
    "        0.5, 0.70,\n",
    "        title_str,\n",
    "        ha=\"center\", va=\"center\",\n",
    "        fontsize=16, weight=\"bold\"\n",
    "    )\n",
    "    ax_title.text(\n",
    "        0.5, 0.20,\n",
    "        subtitle_str,\n",
    "        ha=\"center\", va=\"center\",\n",
    "        fontsize=9, color=\"dimgray\",\n",
    "        linespacing=1.25\n",
    "    )\n",
    "\n",
    "    # ---- Row 1: CPC + CI ----\n",
    "    ax_cpc1 = fig.add_subplot(gs[1, 0])\n",
    "    ax_cpc2 = fig.add_subplot(gs[1, 1], sharey=ax_cpc1)\n",
    "    ax_cpc3 = fig.add_subplot(gs[1, 2], sharey=ax_cpc1)\n",
    "\n",
    "    plot_cpc(ax_cpc1, res_meps, \"MEP-averaged (speaker-equal)\", ylim_cpc, show_legend=True)\n",
    "    plot_cpc(ax_cpc2, res_cap,  \"Speech-capped (per-MEP cap)\", ylim_cpc, show_legend=False)\n",
    "    plot_cpc(ax_cpc3, res_w,    \"Speech-weighted (as heard)\", ylim_cpc, show_legend=True)\n",
    "\n",
    "    for ax in (ax_cpc2, ax_cpc3):\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # ---- Row 2: CPC_adj + CI where available ----\n",
    "    ax_adj1 = fig.add_subplot(gs[2, 0])\n",
    "    ax_adj2 = fig.add_subplot(gs[2, 1], sharey=ax_adj1)\n",
    "    ax_adj3 = fig.add_subplot(gs[2, 2], sharey=ax_adj1)\n",
    "\n",
    "    plot_cpc_adj(ax_adj1, res_meps, \"MEP-averaged — CPC_adj\", ylim_cpc_adj, show_legend=True)\n",
    "    plot_cpc_adj(ax_adj2, res_cap,  \"Speech-capped — CPC_adj\", ylim_cpc_adj, show_legend=False)\n",
    "    plot_cpc_adj(\n",
    "        ax_adj3, res_w,\n",
    "        \"Speech-weighted — CPC_adj\", ylim_cpc_adj,\n",
    "        show_legend=True, note_if_missing=True\n",
    "    )\n",
    "\n",
    "    for ax in (ax_adj2, ax_adj3):\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    # ---- Row 3: heatmaps ----\n",
    "    ax_h1 = fig.add_subplot(gs[3, 0])\n",
    "    ax_h2 = fig.add_subplot(gs[3, 1])\n",
    "    ax_h3 = fig.add_subplot(gs[3, 2])\n",
    "\n",
    "    plot_heatmap(ax_h1, pw_meps, \"Pairwise — MEP-averaged\", vmin, vmax)\n",
    "    plot_heatmap(ax_h2, pw_cap,  \"Pairwise — Speech-capped\", vmin, vmax)\n",
    "    plot_heatmap(ax_h3, pw_w,    \"Pairwise — Speech-weighted\", vmin, vmax)\n",
    "\n",
    "    # ---- Row 4: description block ----\n",
    "    ax_text = fig.add_subplot(gs[4, :])\n",
    "    ax_text.axis(\"off\")\n",
    "\n",
    "    footer_text = (\n",
    "        \"CPC = BSS/TSS: share of variance in de-meaned embeddings explained by party identity\\n\"\n",
    "        \"(higher values = parties sound more distinct). CPC_adj applies a degrees-of-freedom correction,\\n\"\n",
    "        \"analogous to adjusted R²: it penalises apparent separation when there are many dimensions and parties\\n\"\n",
    "        \"relative to the number of speakers, and can be negative when between-party differences are not reliably above chance.\\n\\n\"\n",
    "        \"Pairwise heatmaps show standardized distances between party centroids in the latest valid year.\\n\"\n",
    "        \"Distances are divided by within-party spread, so a value around 1 means two parties are about as far apart as the\\n\"\n",
    "        \"average internal dispersion of their rhetoric; larger numbers indicate stronger rhetorical separation.\"\n",
    "    )\n",
    "\n",
    "    ax_text.text(\n",
    "        0.03, 0.96,\n",
    "        footer_text,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        fontsize=8.5, color=\"dimgray\",\n",
    "        linespacing=1.25\n",
    "    )\n",
    "\n",
    "    # *** GENEROUS PAGE MARGINS so nothing ever gets cut off ***\n",
    "    fig.subplots_adjust(\n",
    "        left=0.09,   # room for y labels & heatmap tick labels\n",
    "        right=0.97,\n",
    "        top=0.93,\n",
    "        bottom=0.13\n",
    "    )\n",
    "\n",
    "    fig.savefig(outpath, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------- rebuild for all topics ----------\n",
    "def rebuild_all_reports_9panels(base_dir=BASE_DIR, topics=TOPICS, include_all=True):\n",
    "    if include_all:\n",
    "        topics_list = [\"ALL\"] + list(topics)\n",
    "    else:\n",
    "        topics_list = list(topics)\n",
    "\n",
    "    for topic in topics_list:\n",
    "        if str(topic).upper() == \"ALL\":\n",
    "            slug = \"_all_speeches\"\n",
    "            pretty_name = \"All speeches\"\n",
    "        else:\n",
    "            slug = _slugify(topic)\n",
    "            pretty_name = topic\n",
    "\n",
    "        topic_dir = os.path.join(base_dir, slug)\n",
    "        if not os.path.isdir(topic_dir):\n",
    "            log(f\"✖ skip {pretty_name} (no folder {topic_dir})\")\n",
    "            continue\n",
    "\n",
    "        def _read_csv_safe(path):\n",
    "            try:\n",
    "                return pd.read_csv(path)\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        res_meps = _read_csv_safe(os.path.join(topic_dir, \"res_meps.csv\"))\n",
    "        res_cap  = _read_csv_safe(os.path.join(topic_dir, \"res_cap.csv\"))\n",
    "        res_w    = _read_csv_safe(os.path.join(topic_dir, \"res_w.csv\"))\n",
    "        pw_meps  = _read_csv_safe(os.path.join(topic_dir, \"pw_meps.csv\"))\n",
    "        pw_cap   = _read_csv_safe(os.path.join(topic_dir, \"pw_cap.csv\"))\n",
    "        pw_w     = _read_csv_safe(os.path.join(topic_dir, \"pw_w.csv\"))\n",
    "\n",
    "        # if we have literally no CPC results for this topic, skip\n",
    "        if res_meps is None and res_cap is None and res_w is None:\n",
    "            log(f\"✖ skip {pretty_name} (no res_*.csv files)\")\n",
    "            continue\n",
    "\n",
    "        out_pdf = os.path.join(topic_dir, \"topic_report_extended.pdf\")\n",
    "        build_topic_report_9panels(\n",
    "            pretty_name,\n",
    "            res_meps, res_cap, res_w,\n",
    "            pw_meps, pw_cap, pw_w,\n",
    "            out_pdf\n",
    "        )\n",
    "\n",
    "    log(\"All 9-panel PDFs rebuilt.\")\n",
    "\n",
    "\n",
    "# --------- RUN THIS ---------\n",
    "if __name__ == \"__main__\":\n",
    "    rebuild_all_reports_9panels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3bf6d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sitting_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "speech_order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "speaker_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "political_group",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "speech_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "macro_topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "specific_focus",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d83e59d4-6d64-463b-a1ba-f609abc9b76c",
       "rows": [
        [
         "0",
         "575688",
         "eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364",
         "2025-07-10",
         "1",
         "President",
         null,
         null,
         "The President has received from the Council its position at first reading regarding amending Directive 2008/98/EC on waste. The President has also received the reasons which led to its adoption and the position and opinion of the Commission. The full title will be published in the minutes of today's sitting. The three-month period available to Parliament to adopt its position begins tomorrow, 11 July 2025.",
         "EN",
         "Council position at first reading",
         "Procedural & Parliamentary business",
         null
        ],
        [
         "1",
         "575689",
         "eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364",
         "2025-07-10",
         "2",
         "President",
         null,
         null,
         "The next item on the agenda is the debate on the Commission statement on the post-2027 common agricultural policy (2025/2791(RSP)).",
         "EN",
         "Post-2027 Common Agricultural Policy",
         "Agriculture & fisheries",
         "CAP post-2027 reform"
        ],
        [
         "2",
         "575690",
         "eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364",
         "2025-07-10",
         "3",
         "Christophe Hansen",
         null,
         "Member of the Commission",
         "Madam President, honourable Members, dear colleagues, thank you very much for putting this important point up for the plenary debate today. I believe this is a testimony of how important the common agricultural policy is for this House. I can reassure you that it is equally important for the European Commission. The CAP is one of our oldest policies at the heart of the European project. In December 1964, Sicco Mansholt stated: 'the governments, the Member countries burnt the individual boats in which they have sailed home to the harbours of national agricultural policy. Henceforth there is only a common policy, a policy of European solidarity.' This statement is as relevant as it was 60 years ago. The CAP is a true common policy, a policy of solidarity, an anchor of European food sovereignty and an integral part of European integration. While in the 1960s, we were rebuilding our continent after the devastation of the war, we are now building a stronger Europe. A stronger Europe, that can withstand the multiple challenges it is facing. The security architecture that we relied on for decades can no longer be taken for granted. Russia's unprovoked aggression has brought war back to our continent. Extreme weather events are more and more frequent due to climate change. The new normal is anything but normal. Therefore, our future budget and our policies must keep pace with that changing world. Yet, if the changing geopolitical realities teach us one thing, it is the strategic importance of food production. You cannot build a strong continent on an empty stomach, ladies and gentlemen. This was the driving force behind Mansholt's policy and it is just as relevant today. Therefore, as the Commission President stated, in our next budget, there will be a central place for cohesion policy and the common agricultural policy. Our regions and our farmers will always be at the heart of the Union. The Commission fully acknowledges that the CAP plays a pivotal and strategic role in maintaining Europe's food sovereignty at all times, in particular in the current challenging geopolitical setting. At the same time, thanks to our farmers, the EU is also a major exporter of food, contributing to global food security. Our farmers and rural areas feel the increasing pressure, from the impact of global uncertainties and climate change to the major challenge of generational renewal. At the same time, they are, as custodians of their land, making great efforts to contribute to our environmental and climate objectives, while ensuring also food security. The Commission's communication, 'The Road to the next Multiannual Financial Framework', clearly puts food security among the key priority areas for funding in the future MFF. But our CAP must be modernised and better adapted to today's challenges. We need a common agricultural policy that is fit for purpose and better targeted, enhances environmental and social outcomes, and fosters thriving rural areas. For this, we have over time built a policy with a coherent toolbox that helps provide a fair income for farmers, safe and affordable food for consumers, and respect for the environment we work in. I fully agree that we need to maintain this coherent toolbox, and the commonness and integrity of the common agricultural policy. I want to reassure you that we are working in this direction. While we should build our future based on our past successes, we need a CAP that is simpler and finds the right balance between incentives, investment and regulation, and must ensure that farmers have a fair and sufficient income. With the simplification package, we have chartered the way for the future CAP by streamlining overlapping requirements and prioritising incentives, building on the current eco‑schemes and agri‑environmental measures, while reducing red tape for our farmers and administrations. We intend to continue on this path and I hope that this Parliament will soon have a common position on that simplification package in order to deliver for our farmers already for the next calendar year. This will be crucial that they feel that our efforts are felt on the farm as well. We will also make sure our policy is better targeted, in particular towards the farmers that actively farm and contribute to our food security and the preservation of the environment. We must improve also the fairness in the distribution of funds. Our tools have to deliver the most disadvantaged sectors and regions. We have many regions in the EU that depend on livestock as the only source of income. The added value the EU can bring to these regions is real and is tangible. Without agricultural activity, land abandonment will cause demographic, environmental and societal problems. In certain regions, we would even have a security problem on top. Look at our eastern border regions that I visited, the Baltics and Finland, which have a common border to Russia, and I have to say, without agriculture and forestry, there would not be much economic activity and human presence left, and that would represent a huge weakness to us. In this sense, these freedom farmers greatly contribute to the EU's line of defence. I would also like to emphasise the crucial role that cohesion policy plays in strengthening our rural areas and regions. Investments in local infrastructure, transport, clean energy, SMEs, broadband, health and education all enhance economic and societal cohesion. This is of growing importance in the context of ensuring the right to stay for all in the place they call home by supporting what a community needs. Furthermore, the mid‑term review of cohesion policy provides incentives and flexibilities for objectives such as water resilience, housing, energy transition, and greater competitiveness and innovation. It also provides specific incentives to eastern border regions, which face the dual challenge of increasing security and relaunching their economies. Furthermore, with the rising uncertainties due to climate and geopolitical impacts, the EU must continue ensuring an adequate safety net for our farmers in the form of risk and crisis management – a true unity safety net to alleviate the pressure and de‑risk the operations of our farmers and food industry. Honourable Members, these elements must, in my view, be recognised when we shape our future policy and also spend the future budget, while we are building on the success of the CAP. This has brought us up here till today. How exactly to do that will be the subject of the discussion with the co‑legislators and with you. Therefore, I look forward as well to hearing your views. In conclusion, I believe that the new financial framework presents an opportunity to build on the current CAP and to strengthen our policy response to achieve competitiveness, resilience, innovation and sustainability objectives in a more effective manner, while also ensuring that solutions are designed by taking into account local specificities and sectorial challenges. Finally, I would like to thank as well especially the agriculture committee for accelerating its work on the own‑initiative report by Ms Crespo Díaz. This will also allow me to take on board the main points and the main requests of this House when it comes to designing the future of our common agricultural policy, and that is how it has to be. I would like to thank you as well for that very valuable contribution.",
         "EN",
         "Post-2027 Common Agricultural Policy",
         "Agriculture & fisheries",
         "CAP post-2027 reform"
        ],
        [
         "3",
         "575691",
         "eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364",
         "2025-07-10",
         "4",
         "Herbert Dorfmann",
         "PPE",
         null,
         "Frau Präsidentin, Herr Kommissar, Kolleginnen und Kollegen! In wenigen Tagen werden wir einen Vorschlag für die GAP und deren Finanzierung bis zum Jahr 2035 auf dem Tisch haben, und ich habe den Eindruck, die Vorzeichen sind – gelinde gesagt – nicht die besten. Da plant man wohl offensichtlich aus jenen Politiken, die bisher das Herz der Europäischen Union ausgemacht haben – die Landwirtschaft, aber auch die Kohäsion, grenzüberschreitende Zusammenarbeit, auch andere –, so eine Art Eintopf zu machen, wo man dann nicht mehr sieht, welche Zutaten im Topf wirklich drinnen sind. Ich habe ein bisschen den Eindruck, es ist, wie wenn man so einen Eintopf kocht: Man will den Topf voll haben, aber nicht zeigen, dass man zu wenig Fleisch hat. Nur zwei Zahlen: Wenn wir die finanzielle Ausstattung der Gemeinsamen Agrarpolitik in absoluten Zahlen unverändert lassen im Verhältnis zu heute, dann wird diese Politik 2035 rund ein Drittel weniger Geld, in Kaufkraft gemessen, haben als 2020. Wenn wir um 15 % kürzen, dann bleibt noch die Hälfte von dem Geld übrig, das wir in Kaufkraft 2020 hatten. Wir hungern die Politik also systematisch aus. Der sichere Zugang zu Lebensmitteln wird aber eine zentrale Herausforderung für die Gesellschaft von morgen werden. Wenn wir in der Europäischen Union nicht mehr bereit sind, in diesen Sektor zu investieren, junge Leute anzuziehen, die bereit sind, in die Landwirtschaft zu gehen, dann werden wir unsere Ernährungssouveränität Schritt für Schritt verlieren. Das bedeutet natürlich nicht, Herr Kommissar, da gebe ich Ihnen recht, dass man nicht auch Veränderungen machen muss in der Politik – und meine Fraktion ist bereit, darüber zu diskutieren und auch zu schauen, wie man Geld effizienter ausgeben kann. Aber wir brauchen keinen Finanzierungseintopf, wir brauchen einen gesicherten und ausreichenden Haushalt für die Landwirtschaft. Und wir brauchen vor allem eine eigenständige Gesetzgebung für die gemeinsame Agrarpolitik und keine generellen Richtlinien für nationale Landwirtschaftspolitiken. Wir brauchen keine Renationalisierung dieser Politik, das würde am Ende auch die Regionen schwächen in der Zuständigkeit. Ich hoffe wirklich, dass wir am nächsten Mittwoch eine selbstbewusste Kommission erleben, eine Kommission, die ihre Kompetenzen verteidigt und die auch ihre Politiken verteidigt und dafür kämpft, dass diese finanziert werden. Herr Kommissar, seien Sie versichert, dann werden wir mit Ihnen kämpfen. Ich werde aber nicht bereit sein, einer Gemeinsamen Agrarpolitik zuzustimmen, welche die europäische Landwirtschaft aufs Spiel setzt.",
         "DE",
         "Post-2027 Common Agricultural Policy",
         "Agriculture & fisheries",
         "CAP post-2027 reform"
        ],
        [
         "4",
         "575692",
         "eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364",
         "2025-07-10",
         "5",
         "Dario Nardella",
         "S&D",
         null,
         "Signora Presidente, signor Commissario, onorevoli colleghi, se ci fosse un taglio del 15 % alla politica agricola comune, noi avremmo -217 miliardi di euro rispetto... (L'oratore mostra all'assemblea un cartello con delle cifre)",
         "IT",
         "Post-2027 Common Agricultural Policy",
         "Agriculture & fisheries",
         "CAP post-2027 reform"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sitting_id</th>\n",
       "      <th>date</th>\n",
       "      <th>speech_order</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>political_group</th>\n",
       "      <th>title</th>\n",
       "      <th>speech_content</th>\n",
       "      <th>language</th>\n",
       "      <th>topic</th>\n",
       "      <th>macro_topic</th>\n",
       "      <th>specific_focus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>575688</td>\n",
       "      <td>eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>1</td>\n",
       "      <td>President</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The President has received from the Council it...</td>\n",
       "      <td>EN</td>\n",
       "      <td>Council position at first reading</td>\n",
       "      <td>Procedural &amp; Parliamentary business</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575689</td>\n",
       "      <td>eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>2</td>\n",
       "      <td>President</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The next item on the agenda is the debate on t...</td>\n",
       "      <td>EN</td>\n",
       "      <td>Post-2027 Common Agricultural Policy</td>\n",
       "      <td>Agriculture &amp; fisheries</td>\n",
       "      <td>CAP post-2027 reform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>575690</td>\n",
       "      <td>eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>3</td>\n",
       "      <td>Christophe Hansen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Member of the Commission</td>\n",
       "      <td>Madam President, honourable Members, dear coll...</td>\n",
       "      <td>EN</td>\n",
       "      <td>Post-2027 Common Agricultural Policy</td>\n",
       "      <td>Agriculture &amp; fisheries</td>\n",
       "      <td>CAP post-2027 reform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>575691</td>\n",
       "      <td>eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>4</td>\n",
       "      <td>Herbert Dorfmann</td>\n",
       "      <td>PPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frau Präsidentin, Herr Kommissar, Kolleginnen ...</td>\n",
       "      <td>DE</td>\n",
       "      <td>Post-2027 Common Agricultural Policy</td>\n",
       "      <td>Agriculture &amp; fisheries</td>\n",
       "      <td>CAP post-2027 reform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>575692</td>\n",
       "      <td>eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Dario Nardella</td>\n",
       "      <td>S&amp;D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Signora Presidente, signor Commissario, onorev...</td>\n",
       "      <td>IT</td>\n",
       "      <td>Post-2027 Common Agricultural Policy</td>\n",
       "      <td>Agriculture &amp; fisheries</td>\n",
       "      <td>CAP post-2027 reform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                        sitting_id        date  \\\n",
       "0  575688  eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364  2025-07-10   \n",
       "1  575689  eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364  2025-07-10   \n",
       "2  575690  eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364  2025-07-10   \n",
       "3  575691  eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364  2025-07-10   \n",
       "4  575692  eli/dl/event/MTG-PL-2025-07-10-OTH-2017033239364  2025-07-10   \n",
       "\n",
       "   speech_order       speaker_name political_group                     title  \\\n",
       "0             1          President             NaN                       NaN   \n",
       "1             2          President             NaN                       NaN   \n",
       "2             3  Christophe Hansen             NaN  Member of the Commission   \n",
       "3             4   Herbert Dorfmann             PPE                       NaN   \n",
       "4             5     Dario Nardella             S&D                       NaN   \n",
       "\n",
       "                                      speech_content language  \\\n",
       "0  The President has received from the Council it...       EN   \n",
       "1  The next item on the agenda is the debate on t...       EN   \n",
       "2  Madam President, honourable Members, dear coll...       EN   \n",
       "3  Frau Präsidentin, Herr Kommissar, Kolleginnen ...       DE   \n",
       "4  Signora Presidente, signor Commissario, onorev...       IT   \n",
       "\n",
       "                                  topic                          macro_topic  \\\n",
       "0     Council position at first reading  Procedural & Parliamentary business   \n",
       "1  Post-2027 Common Agricultural Policy              Agriculture & fisheries   \n",
       "2  Post-2027 Common Agricultural Policy              Agriculture & fisheries   \n",
       "3  Post-2027 Common Agricultural Policy              Agriculture & fisheries   \n",
       "4  Post-2027 Common Agricultural Policy              Agriculture & fisheries   \n",
       "\n",
       "         specific_focus  \n",
       "0                   NaN  \n",
       "1  CAP post-2027 reform  \n",
       "2  CAP post-2027 reform  \n",
       "3  CAP post-2027 reform  \n",
       "4  CAP post-2027 reform  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d32a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 10000 speeches. Average words per speech (first 10000): 190.72\n"
     ]
    }
   ],
   "source": [
    "# compute average number of words for speech_content of first 500 speeches\n",
    "n = min(10000, len(df))\n",
    "texts = df[\"speech_content\"].astype(str).iloc[:n].map(_scrub_boiler)  # use existing scrubber\n",
    "word_counts = texts.map(lambda t: len(t.split()))\n",
    "avg_words_first_500 = float(word_counts.mean())\n",
    "\n",
    "print(f\"Counted {n} speeches. Average words per speech (first {n}): {avg_words_first_500:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83fb75be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sitting_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "speech_order",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "speaker_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "political_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "speech_content",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "macro_topic",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "specific_focus",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1ed51dd6-5ea4-4077-82d1-d7765b279dda",
       "rows": [
        [
         "24296",
         "620840",
         "eli/dl/event/MTG-PL-2023-11-21-OTH-25530000",
         "2023-11-21",
         "376",
         "Ernő Schaller-Baross",
         "NI",
         "Frage nach dem Verfahren der „blauen Karte“",
         "Herr Freund! Sie haben fünf Jahre für die Soros-Foundation gearbeitet und Sie reden da über Antisemitismus? In Ihrer grünen Regierung bei Ihnen in Deutschland dürfen und können Juden und Jüdinnen nicht mehr frei auf die Straße wegen der massenhaften Migration, die Sie nach Deutschland geschleppt haben – können die Leute nicht frei reden, frei auf die Straße gehen oder gar in ihre Kirchen gehen. Ich frage Sie ganz offen: Sollten Sie sich nicht ein bisschen eher mit Deutschland, mit Ihrer deutschen Regierung und mit den Vorkommnissen in Deutschland gegen Juden und Jüdinnen beschäftigen?",
         "DE",
         "Continuing threat to the rule of law, the independence of justice and the non-fulfilment of conditionality for EU funding in Hungary",
         "Rule of law & fundamental rights",
         "Hungary: rule of law & funding conditionality"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sitting_id</th>\n",
       "      <th>date</th>\n",
       "      <th>speech_order</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>political_group</th>\n",
       "      <th>title</th>\n",
       "      <th>speech_content</th>\n",
       "      <th>language</th>\n",
       "      <th>topic</th>\n",
       "      <th>macro_topic</th>\n",
       "      <th>specific_focus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24296</th>\n",
       "      <td>620840</td>\n",
       "      <td>eli/dl/event/MTG-PL-2023-11-21-OTH-25530000</td>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>376</td>\n",
       "      <td>Ernő Schaller-Baross</td>\n",
       "      <td>NI</td>\n",
       "      <td>Frage nach dem Verfahren der „blauen Karte“</td>\n",
       "      <td>Herr Freund! Sie haben fünf Jahre für die Soro...</td>\n",
       "      <td>DE</td>\n",
       "      <td>Continuing threat to the rule of law, the inde...</td>\n",
       "      <td>Rule of law &amp; fundamental rights</td>\n",
       "      <td>Hungary: rule of law &amp; funding conditionality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                   sitting_id        date  \\\n",
       "24296  620840  eli/dl/event/MTG-PL-2023-11-21-OTH-25530000  2023-11-21   \n",
       "\n",
       "       speech_order          speaker_name political_group  \\\n",
       "24296           376  Ernő Schaller-Baross              NI   \n",
       "\n",
       "                                             title  \\\n",
       "24296  Frage nach dem Verfahren der „blauen Karte“   \n",
       "\n",
       "                                          speech_content language  \\\n",
       "24296  Herr Freund! Sie haben fünf Jahre für die Soro...       DE   \n",
       "\n",
       "                                                   topic  \\\n",
       "24296  Continuing threat to the rule of law, the inde...   \n",
       "\n",
       "                            macro_topic  \\\n",
       "24296  Rule of law & fundamental rights   \n",
       "\n",
       "                                      specific_focus  \n",
       "24296  Hungary: rule of law & funding conditionality  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give me the row with id = 620840\n",
    "df[df[\"id\"] == 620840]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0dee00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
